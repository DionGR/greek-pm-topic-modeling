{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a671e359e5d8c5b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finding the Best Hyperparameters for BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7bb6e08577a63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this notebook we will try to find the best hyperparameters for our BERTopic model, by trying different configurations of UMAP and HDBSCAN models. Then we will evaluate each model based on both standard evaluation metrics and manual inspection of the topics created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eb939",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56643b81",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.bertopic_evaluator import BERTopicModelEvaluator\n",
    "from config.model import NUM_TOPICS, TOP_K, EMBEDDING_MODEL, vectorizer_params, c_tfidf_params, metrics\n",
    "from config.optimization import all_config_combinations, algos_dict\n",
    "\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129e722882e061e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = DataLoader('../../data/data_speeches.csv', '../../data/data_statements.csv', split_data=False)\n",
    "loader.process()\n",
    "\n",
    "train_docs, train_sentences = loader.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6850f97",
   "metadata": {},
   "source": [
    "For this step, we only need the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66810a73",
   "metadata": {},
   "source": [
    "## Constant Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20f629",
   "metadata": {},
   "source": [
    "We will use the same vectorizer, c-TF-IDF model and sentence transformer model for all our experiments. \n",
    "\n",
    "We're interesting in optimizing on the Dimensionality Reduction and Clustering models, so we will keep the rest of the pipeline constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504e80f2c0e4d0be",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(**vectorizer_params)\n",
    "ctfidf_model = ClassTfidfTransformer(**c_tfidf_params)\n",
    "st_model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d7c61fc44f47d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluating different UMAP and HDBSCAN configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580d89e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8003511",
   "metadata": {},
   "source": [
    "Let's see how many different configurations we can try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f382c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space = all_config_combinations()\n",
    "len(search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014afb5",
   "metadata": {},
   "source": [
    "Start from checkpointed model - paste last model that was being trained before the crash as a string. Example in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bcc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from = \"model_UMAP_{'n_components': 15, 'n_neighbors': 5, 'min_dist': 0.1}_HDBSCAN_{'min_cluster_size': 7, 'metric': 'euclidean', 'prediction_data': False}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9241b",
   "metadata": {},
   "source": [
    "Do not touch, **uncomment only if you want to start from a checkpointed model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f832ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from 100\n"
     ]
    }
   ],
   "source": [
    "for i, config in enumerate(search_space):\n",
    "    model_name = f\"model_{config['dim_reduction_model']}_{config['dim_reduction_params']}_{config['clustering_model']}_{config['clustering_params']}\"\n",
    "    if model_name == start_from:\n",
    "        start_from = i\n",
    "        break\n",
    "    \n",
    "print(f\"Starting from {start_from}\")\n",
    "search_space = search_space[start_from:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b31b1",
   "metadata": {},
   "source": [
    "### Document Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48084f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = 'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a287cb8fdeb5d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "print(\"Loading models...\")\n",
    "\n",
    "for config in search_space:\n",
    "    dim_reduction_model = algos_dict[config['dim_reduction_model']](**config['dim_reduction_params'])\n",
    "    clustering_model = algos_dict[config['clustering_model']](**config['clustering_params'])\n",
    "        \n",
    "    model_name = f\"model_{config['dim_reduction_model']}_{config['dim_reduction_params']}_{config['clustering_model']}_{config['clustering_params']}\"\n",
    "\n",
    "\n",
    "    model = BERTopic(\n",
    "        umap_model=dim_reduction_model,\n",
    "        hdbscan_model=clustering_model,\n",
    "        embedding_model=EMBEDDING_MODEL,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        nr_topics=NUM_TOPICS,\n",
    "        top_n_words=TOP_K,\n",
    "    )\n",
    "\n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dba14b84c67bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = BERTopicModelEvaluator(\n",
    "                                   models=models, \n",
    "                                   metrics=metrics, \n",
    "                                   dataset=train_docs,\n",
    "                                   topics=NUM_TOPICS,\n",
    "                                   top_k=TOP_K,\n",
    "                                   granularity=granularity\n",
    "                                   )           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb14361500f3ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating models...\")\n",
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
