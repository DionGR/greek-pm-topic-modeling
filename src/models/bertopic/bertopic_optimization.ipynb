{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a671e359e5d8c5b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finding the Best Hyperparameters for BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7bb6e08577a63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this notebook we will try to find the best hyperparameters for our BERTopic model, by trying different configurations of UMAP and HDBSCAN models. Then we will evaluate each model based on both standard evaluation metrics and manual inspection of the topics created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eb939",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56643b81",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.bertopic_evaluator import BERTopicModelEvaluator\n",
    "from config.model import NUM_TOPICS, TOP_K, EMBEDDING_MODEL, vectorizer_params, c_tfidf_params, metrics\n",
    "from config.optimization import all_config_combinations, algos_dict\n",
    "\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129e722882e061e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = DataLoader('../../data/data_speeches.csv', '../../data/data_statements.csv', split_data=False)\n",
    "loader.process()\n",
    "\n",
    "train_docs, train_sentences = loader.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6850f97",
   "metadata": {},
   "source": [
    "For this step, we only need the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66810a73",
   "metadata": {},
   "source": [
    "## Constant Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20f629",
   "metadata": {},
   "source": [
    "We will use the same vectorizer, c-TF-IDF model and sentence transformer model for all our experiments. \n",
    "\n",
    "We're interesting in optimizing on the Dimensionality Reduction and Clustering models, so we will keep the rest of the pipeline constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504e80f2c0e4d0be",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(**vectorizer_params)\n",
    "ctfidf_model = ClassTfidfTransformer(**c_tfidf_params)\n",
    "st_model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d7c61fc44f47d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluating different UMAP and HDBSCAN configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580d89e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8003511",
   "metadata": {},
   "source": [
    "Let's see how many different configurations we can try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f382c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space = all_config_combinations()\n",
    "len(search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014afb5",
   "metadata": {},
   "source": [
    "Start from checkpointed model - paste last model that was being trained before the crash as a string. Example in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72bcc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from = \"model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9241b",
   "metadata": {},
   "source": [
    "Do not touch, **uncomment only if you want to start from a checkpointed model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f832ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from 2\n"
     ]
    }
   ],
   "source": [
    "for i, config in enumerate(search_space):\n",
    "    model_name = f\"model_{config['dim_reduction_model']}_{config['dim_reduction_params']}_{config['clustering_model']}_{config['clustering_params']}\"\n",
    "    if model_name == start_from:\n",
    "        start_from = i\n",
    "        break\n",
    "    \n",
    "print(f\"Starting from {start_from}\")\n",
    "search_space = search_space[start_from:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b31b1",
   "metadata": {},
   "source": [
    "### Document Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48084f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = 'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93a287cb8fdeb5d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "print(\"Loading models...\")\n",
    "\n",
    "for config in search_space:\n",
    "    dim_reduction_model = algos_dict[config['dim_reduction_model']](**config['dim_reduction_params'])\n",
    "    clustering_model = algos_dict[config['clustering_model']](**config['clustering_params'])\n",
    "        \n",
    "    model_name = f\"model_{config['dim_reduction_model']}_{config['dim_reduction_params']}_{config['clustering_model']}_{config['clustering_params']}\"\n",
    "\n",
    "\n",
    "    model = BERTopic(\n",
    "        umap_model=dim_reduction_model,\n",
    "        hdbscan_model=clustering_model,\n",
    "        embedding_model=EMBEDDING_MODEL,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        nr_topics=NUM_TOPICS,\n",
    "        top_n_words=TOP_K,\n",
    "    )\n",
    "\n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68dba14b84c67bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = BERTopicModelEvaluator(\n",
    "                                   models=models, \n",
    "                                   metrics=metrics, \n",
    "                                   dataset=train_docs,\n",
    "                                   topics=NUM_TOPICS,\n",
    "                                   top_k=TOP_K,\n",
    "                                   granularity=granularity\n",
    "                                   )                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aeb14361500f3ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n",
      "Training model:  model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Model training complete.\n",
      "Evaluating model:  model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric coherence_c_npmi for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric coherence_c_v for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric coherence_u_mass for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric coherence_c_uci for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric diversity_topic for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric similarity_rbo for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n",
      "Evaluating metric similarity_pjs for model model_UMAP_{'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.05}_HDBSCAN_{'min_cluster_size': 15, 'metric': 'euclidean', 'prediction_data': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-dion.rigatos@gmail.com/My Drive/Archivio/University/Classes/Erasmus Courses/NLP/NLP Project/greek-pm-topic-modeling/src/models/bertopic/utils/bertopic_evaluator.py:76\u001b[0m, in \u001b[0;36mBERTopicModelEvaluator.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_type, metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating metric \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     model_metric_data[metric_type] \u001b[38;5;241m=\u001b[39m [score]\n\u001b[1;32m     79\u001b[0m metric_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(model_metric_data)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/octis/evaluation_metrics/similarity_metrics.py:258\u001b[0m, in \u001b[0;36mPairwiseJaccardSimilarity.score\u001b[0;34m(self, model_output)\u001b[0m\n\u001b[1;32m    256\u001b[0m     count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    257\u001b[0m     sim \u001b[38;5;241m=\u001b[39m sim \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mfloat\u001b[39m(intersection) \u001b[38;5;241m/\u001b[39m union)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating models...\")\n",
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
