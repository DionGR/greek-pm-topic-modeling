{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.models.LDA import LDA\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "\n",
    "from spacy.lang.el.stop_words import STOP_WORDS as el_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeches_df = pd.read_csv('data/data_speeches.csv')\n",
    "statements_df = pd.read_csv('data/data_statements.csv')\n",
    "\n",
    "# merge the two datasets\n",
    "# df = pd.concat([speeches_df, statements_df], ignore_index=True)\n",
    "df = statements_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>33634</td>\n",
       "      <td>https://www.primeminister.gr/2024/02/15/33634</td>\n",
       "      <td>Ενημερωτικό σημείωμα για τη συνάντηση του Πρωθ...</td>\n",
       "      <td>Ο Πρωθυπουργός Κυριάκος Μητσοτάκης συναντήθηκε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>31311</td>\n",
       "      <td>https://www.primeminister.gr/2023/02/15/31311</td>\n",
       "      <td>Συνάντηση του Πρωθυπουργού Κυριάκου Μητσοτάκη ...</td>\n",
       "      <td>Κυρίες και κύριοι, είναι πραγματικά δύσκολο να...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>28429</td>\n",
       "      <td>https://www.primeminister.gr/2022/01/26/28429</td>\n",
       "      <td>Εισαγωγική τοποθέτηση του Πρωθυπουργού Κυριάκο...</td>\n",
       "      <td>Καλημέρα σας. Θέλω να ξεκινήσω ζητώντας μία πρ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>32175</td>\n",
       "      <td>https://www.primeminister.gr/2023/07/13/32175</td>\n",
       "      <td>Δήλωση του Πρωθυπουργού Κυριάκου Μητσοτάκη κατ...</td>\n",
       "      <td>Χαίρομαι πολύ κυρία Υπουργέ, κύριε Aναπληρωτά,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>27679</td>\n",
       "      <td>https://www.primeminister.gr/2021/10/11/27679</td>\n",
       "      <td>Ενημερωτικό σημείωμα για τη συνάντηση του Πρωθ...</td>\n",
       "      <td>Ο Πρωθυπουργός Κυριάκος Μητσοτάκης συναντήθηκε...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     id                                            url  \\\n",
       "19   2024-02-15  33634  https://www.primeminister.gr/2024/02/15/33634   \n",
       "138  2023-02-15  31311  https://www.primeminister.gr/2023/02/15/31311   \n",
       "276  2022-01-26  28429  https://www.primeminister.gr/2022/01/26/28429   \n",
       "104  2023-07-13  32175  https://www.primeminister.gr/2023/07/13/32175   \n",
       "329  2021-10-11  27679  https://www.primeminister.gr/2021/10/11/27679   \n",
       "\n",
       "                                                 title  \\\n",
       "19   Ενημερωτικό σημείωμα για τη συνάντηση του Πρωθ...   \n",
       "138  Συνάντηση του Πρωθυπουργού Κυριάκου Μητσοτάκη ...   \n",
       "276  Εισαγωγική τοποθέτηση του Πρωθυπουργού Κυριάκο...   \n",
       "104  Δήλωση του Πρωθυπουργού Κυριάκου Μητσοτάκη κατ...   \n",
       "329  Ενημερωτικό σημείωμα για τη συνάντηση του Πρωθ...   \n",
       "\n",
       "                                                  text  \n",
       "19   Ο Πρωθυπουργός Κυριάκος Μητσοτάκης συναντήθηκε...  \n",
       "138  Κυρίες και κύριοι, είναι πραγματικά δύσκολο να...  \n",
       "276  Καλημέρα σας. Θέλω να ξεκινήσω ζητώντας μία πρ...  \n",
       "104  Χαίρομαι πολύ κυρία Υπουργέ, κύριε Aναπληρωτά,...  \n",
       "329  Ο Πρωθυπουργός Κυριάκος Μητσοτάκης συναντήθηκε...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Η Σύνοδος Κορυφής η οποία θα ξεκινήσει σε λίγο...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ο Πρωθυπουργός Κυριάκος Μητσοτάκης επισκέφθηκε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Σε λίγο αφήνουμε πίσω το 2023, των δοκιμασιών ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Ο Πρωθυπουργός Κυριάκος Μητσοτάκης συναντήθηκε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>«Σήμερα θα καθορίσουμε την κυβερνητική πολιτικ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "45   Η Σύνοδος Κορυφής η οποία θα ξεκινήσει σε λίγο...\n",
       "75   Ο Πρωθυπουργός Κυριάκος Μητσοτάκης επισκέφθηκε...\n",
       "41   Σε λίγο αφήνουμε πίσω το 2023, των δοκιμασιών ...\n",
       "354  Ο Πρωθυπουργός Κυριάκος Μητσοτάκης συναντήθηκε...\n",
       "114  «Σήμερα θα καθορίσουμε την κυβερνητική πολιτικ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop date, id, url, title \n",
    "df = df.drop(columns=['date', 'id', 'url', 'title'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the merged dataset\n",
    "df.to_csv('data/data_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3d07c264134282959e721928fe3a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "4208\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "# Initialize preprocessing\n",
    "preprocessor = Preprocessing(vocabulary=None, language='greek', \n",
    "                             remove_stopwords_spacy=True,\n",
    "                             lemmatize=True, lowercase=True, \n",
    "                             punctuation=string.punctuation, remove_punctuation=True, remove_numbers=True,\n",
    "                             max_df=0.2, min_df=0.01, min_chars=4,  min_words_docs=20, \n",
    "                             verbose=True, num_processes=8, save_original_indexes=True)\n",
    "# preprocess\n",
    "dataset = preprocessor.preprocess_dataset(documents_path='data/data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "dataset.save('data/data_merged_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [305/30500]\tTrain Loss: 1444.5303278688525\tTime: 0:00:00.045838\n",
      "Epoch: [1/100]\tSamples: [66/6600]\tValidation Loss: 1241.4580318566525\tTime: 0:00:00.003338\n",
      "Epoch: [2/100]\tSamples: [610/30500]\tTrain Loss: 1443.8265496926228\tTime: 0:00:00.037000\n",
      "Epoch: [2/100]\tSamples: [66/6600]\tValidation Loss: 1259.1705914121685\tTime: 0:00:00.004044\n",
      "Epoch: [3/100]\tSamples: [915/30500]\tTrain Loss: 1440.0033299180327\tTime: 0:00:00.032121\n",
      "Epoch: [3/100]\tSamples: [66/6600]\tValidation Loss: 1265.2659431226325\tTime: 0:00:00.002990\n",
      "Epoch: [4/100]\tSamples: [1220/30500]\tTrain Loss: 1442.3022797131148\tTime: 0:00:00.030780\n",
      "Epoch: [4/100]\tSamples: [66/6600]\tValidation Loss: 1253.6546630859375\tTime: 0:00:00.004241\n",
      "Epoch: [5/100]\tSamples: [1525/30500]\tTrain Loss: 1447.5812243852458\tTime: 0:00:00.031492\n",
      "Epoch: [5/100]\tSamples: [66/6600]\tValidation Loss: 1247.0808549360795\tTime: 0:00:00.002955\n",
      "Epoch: [6/100]\tSamples: [1830/30500]\tTrain Loss: 1432.5355532786884\tTime: 0:00:00.029653\n",
      "Epoch: [6/100]\tSamples: [66/6600]\tValidation Loss: 1240.9647346265388\tTime: 0:00:00.003585\n",
      "Epoch: [7/100]\tSamples: [2135/30500]\tTrain Loss: 1421.7626024590163\tTime: 0:00:00.034069\n",
      "Epoch: [7/100]\tSamples: [66/6600]\tValidation Loss: 1235.1887539950285\tTime: 0:00:00.002750\n",
      "Epoch: [8/100]\tSamples: [2440/30500]\tTrain Loss: 1432.339856557377\tTime: 0:00:00.031948\n",
      "Epoch: [8/100]\tSamples: [66/6600]\tValidation Loss: 1232.358243075284\tTime: 0:00:00.003804\n",
      "Epoch: [9/100]\tSamples: [2745/30500]\tTrain Loss: 1428.279713114754\tTime: 0:00:00.037012\n",
      "Epoch: [9/100]\tSamples: [66/6600]\tValidation Loss: 1231.4521373401988\tTime: 0:00:00.003531\n",
      "Epoch: [10/100]\tSamples: [3050/30500]\tTrain Loss: 1419.110963114754\tTime: 0:00:00.036206\n",
      "Epoch: [10/100]\tSamples: [66/6600]\tValidation Loss: 1228.884158972538\tTime: 0:00:00.003390\n",
      "Epoch: [11/100]\tSamples: [3355/30500]\tTrain Loss: 1419.2255635245901\tTime: 0:00:00.036932\n",
      "Epoch: [11/100]\tSamples: [66/6600]\tValidation Loss: 1226.0207186612215\tTime: 0:00:00.004463\n",
      "Epoch: [12/100]\tSamples: [3660/30500]\tTrain Loss: 1413.2661116803279\tTime: 0:00:00.038813\n",
      "Epoch: [12/100]\tSamples: [66/6600]\tValidation Loss: 1224.4295395359848\tTime: 0:00:00.003154\n",
      "Epoch: [13/100]\tSamples: [3965/30500]\tTrain Loss: 1415.747899590164\tTime: 0:00:00.032324\n",
      "Epoch: [13/100]\tSamples: [66/6600]\tValidation Loss: 1218.2403675426137\tTime: 0:00:00.003120\n",
      "Epoch: [14/100]\tSamples: [4270/30500]\tTrain Loss: 1411.9570696721312\tTime: 0:00:00.033411\n",
      "Epoch: [14/100]\tSamples: [66/6600]\tValidation Loss: 1212.6360603101325\tTime: 0:00:00.004605\n",
      "Epoch: [15/100]\tSamples: [4575/30500]\tTrain Loss: 1414.7760245901638\tTime: 0:00:00.031769\n",
      "Epoch: [15/100]\tSamples: [66/6600]\tValidation Loss: 1208.499249082623\tTime: 0:00:00.003348\n",
      "Epoch: [16/100]\tSamples: [4880/30500]\tTrain Loss: 1412.196670081967\tTime: 0:00:00.033477\n",
      "Epoch: [16/100]\tSamples: [66/6600]\tValidation Loss: 1203.9803207859848\tTime: 0:00:00.003374\n",
      "Epoch: [17/100]\tSamples: [5185/30500]\tTrain Loss: 1402.3313780737706\tTime: 0:00:00.033440\n",
      "Epoch: [17/100]\tSamples: [66/6600]\tValidation Loss: 1203.8728138316762\tTime: 0:00:00.003364\n",
      "Epoch: [18/100]\tSamples: [5490/30500]\tTrain Loss: 1419.3478227459016\tTime: 0:00:00.049697\n",
      "Epoch: [18/100]\tSamples: [66/6600]\tValidation Loss: 1198.4517776026871\tTime: 0:00:00.003481\n",
      "Epoch: [19/100]\tSamples: [5795/30500]\tTrain Loss: 1403.018493852459\tTime: 0:00:00.031841\n",
      "Epoch: [19/100]\tSamples: [66/6600]\tValidation Loss: 1198.721113725142\tTime: 0:00:00.003314\n",
      "Epoch: [20/100]\tSamples: [6100/30500]\tTrain Loss: 1410.925794057377\tTime: 0:00:00.030500\n",
      "Epoch: [20/100]\tSamples: [66/6600]\tValidation Loss: 1196.863310842803\tTime: 0:00:00.003503\n",
      "Epoch: [21/100]\tSamples: [6405/30500]\tTrain Loss: 1398.879674692623\tTime: 0:00:00.029497\n",
      "Epoch: [21/100]\tSamples: [66/6600]\tValidation Loss: 1197.1834050958807\tTime: 0:00:00.002963\n",
      "Epoch: [22/100]\tSamples: [6710/30500]\tTrain Loss: 1396.0944159836065\tTime: 0:00:00.030628\n",
      "Epoch: [22/100]\tSamples: [66/6600]\tValidation Loss: 1198.691036339962\tTime: 0:00:00.004600\n",
      "Epoch: [23/100]\tSamples: [7015/30500]\tTrain Loss: 1394.2886782786886\tTime: 0:00:00.034337\n",
      "Epoch: [23/100]\tSamples: [66/6600]\tValidation Loss: 1196.8362537730825\tTime: 0:00:00.003763\n",
      "Epoch: [24/100]\tSamples: [7320/30500]\tTrain Loss: 1394.0735911885247\tTime: 0:00:00.028731\n",
      "Epoch: [24/100]\tSamples: [66/6600]\tValidation Loss: 1196.7380445075758\tTime: 0:00:00.002771\n",
      "Epoch: [25/100]\tSamples: [7625/30500]\tTrain Loss: 1403.1962346311475\tTime: 0:00:00.026297\n",
      "Epoch: [25/100]\tSamples: [66/6600]\tValidation Loss: 1195.4705792051373\tTime: 0:00:00.003210\n",
      "Epoch: [26/100]\tSamples: [7930/30500]\tTrain Loss: 1386.2311219262294\tTime: 0:00:00.030837\n",
      "Epoch: [26/100]\tSamples: [66/6600]\tValidation Loss: 1195.9992157907197\tTime: 0:00:00.002901\n",
      "Epoch: [27/100]\tSamples: [8235/30500]\tTrain Loss: 1400.6411116803279\tTime: 0:00:00.031724\n",
      "Epoch: [27/100]\tSamples: [66/6600]\tValidation Loss: 1194.959520744555\tTime: 0:00:00.002663\n",
      "Epoch: [28/100]\tSamples: [8540/30500]\tTrain Loss: 1388.19743852459\tTime: 0:00:00.031461\n",
      "Epoch: [28/100]\tSamples: [66/6600]\tValidation Loss: 1194.9961381392045\tTime: 0:00:00.003067\n",
      "Epoch: [29/100]\tSamples: [8845/30500]\tTrain Loss: 1384.8482581967214\tTime: 0:00:00.030888\n",
      "Epoch: [29/100]\tSamples: [66/6600]\tValidation Loss: 1194.1254272460938\tTime: 0:00:00.003448\n",
      "Epoch: [30/100]\tSamples: [9150/30500]\tTrain Loss: 1388.6404456967214\tTime: 0:00:00.028115\n",
      "Epoch: [30/100]\tSamples: [66/6600]\tValidation Loss: 1194.7946462920218\tTime: 0:00:00.003574\n",
      "Epoch: [31/100]\tSamples: [9455/30500]\tTrain Loss: 1380.2816854508196\tTime: 0:00:00.036187\n",
      "Epoch: [31/100]\tSamples: [66/6600]\tValidation Loss: 1192.393036813447\tTime: 0:00:00.005541\n",
      "Epoch: [32/100]\tSamples: [9760/30500]\tTrain Loss: 1377.8439805327869\tTime: 0:00:00.027284\n",
      "Epoch: [32/100]\tSamples: [66/6600]\tValidation Loss: 1192.5872987689395\tTime: 0:00:00.002960\n",
      "Epoch: [33/100]\tSamples: [10065/30500]\tTrain Loss: 1386.985911885246\tTime: 0:00:00.028515\n",
      "Epoch: [33/100]\tSamples: [66/6600]\tValidation Loss: 1192.3114864464962\tTime: 0:00:00.003070\n",
      "Epoch: [34/100]\tSamples: [10370/30500]\tTrain Loss: 1377.0061219262295\tTime: 0:00:00.032348\n",
      "Epoch: [34/100]\tSamples: [66/6600]\tValidation Loss: 1194.2970155658145\tTime: 0:00:00.004456\n",
      "Epoch: [35/100]\tSamples: [10675/30500]\tTrain Loss: 1384.1017930327869\tTime: 0:00:00.029949\n",
      "Epoch: [35/100]\tSamples: [66/6600]\tValidation Loss: 1192.209247011127\tTime: 0:00:00.003172\n",
      "Epoch: [36/100]\tSamples: [10980/30500]\tTrain Loss: 1381.8316854508196\tTime: 0:00:00.025300\n",
      "Epoch: [36/100]\tSamples: [66/6600]\tValidation Loss: 1192.8174734404593\tTime: 0:00:00.002853\n",
      "Epoch: [37/100]\tSamples: [11285/30500]\tTrain Loss: 1377.7451972336066\tTime: 0:00:00.033169\n",
      "Epoch: [37/100]\tSamples: [66/6600]\tValidation Loss: 1191.6896158854167\tTime: 0:00:00.002957\n",
      "Epoch: [38/100]\tSamples: [11590/30500]\tTrain Loss: 1372.3045081967214\tTime: 0:00:00.027311\n",
      "Epoch: [38/100]\tSamples: [66/6600]\tValidation Loss: 1192.8126923532197\tTime: 0:00:00.003199\n",
      "Epoch: [39/100]\tSamples: [11895/30500]\tTrain Loss: 1393.4324795081968\tTime: 0:00:00.029527\n",
      "Epoch: [39/100]\tSamples: [66/6600]\tValidation Loss: 1193.4594023733428\tTime: 0:00:00.002912\n",
      "Epoch: [40/100]\tSamples: [12200/30500]\tTrain Loss: 1374.779713114754\tTime: 0:00:00.028681\n",
      "Epoch: [40/100]\tSamples: [66/6600]\tValidation Loss: 1190.9531619910038\tTime: 0:00:00.003335\n",
      "Epoch: [41/100]\tSamples: [12505/30500]\tTrain Loss: 1379.0077612704918\tTime: 0:00:00.039512\n",
      "Epoch: [41/100]\tSamples: [66/6600]\tValidation Loss: 1190.3137965346828\tTime: 0:00:00.003385\n",
      "Epoch: [42/100]\tSamples: [12810/30500]\tTrain Loss: 1372.911168032787\tTime: 0:00:00.028985\n",
      "Epoch: [42/100]\tSamples: [66/6600]\tValidation Loss: 1190.348203716856\tTime: 0:00:00.002992\n",
      "Epoch: [43/100]\tSamples: [13115/30500]\tTrain Loss: 1374.4580174180328\tTime: 0:00:00.032030\n",
      "Epoch: [43/100]\tSamples: [66/6600]\tValidation Loss: 1192.0414798620975\tTime: 0:00:00.004432\n",
      "Epoch: [44/100]\tSamples: [13420/30500]\tTrain Loss: 1372.2836962090164\tTime: 0:00:00.033591\n",
      "Epoch: [44/100]\tSamples: [66/6600]\tValidation Loss: 1191.9743800307765\tTime: 0:00:00.003052\n",
      "Epoch: [45/100]\tSamples: [13725/30500]\tTrain Loss: 1386.0509221311474\tTime: 0:00:00.029465\n",
      "Epoch: [45/100]\tSamples: [66/6600]\tValidation Loss: 1192.4567834102745\tTime: 0:00:00.003287\n",
      "Epoch: [46/100]\tSamples: [14030/30500]\tTrain Loss: 1371.570568647541\tTime: 0:00:00.034132\n",
      "Epoch: [46/100]\tSamples: [66/6600]\tValidation Loss: 1190.403828938802\tTime: 0:00:00.003670\n",
      "Early stopping\n",
      "topics\n",
      "topic-document-matrix\n",
      "topic-word-matrix\n",
      "test-topic-document-matrix\n"
     ]
    }
   ],
   "source": [
    "model = NeuralLDA(num_topics=25, num_layers=4, num_neurons=256)\n",
    "\n",
    "output = model.train_model(dataset)\n",
    "\n",
    "print(*list(output.keys()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['topics', 'topic-document-matrix', 'topic-word-matrix', 'test-topic-document-matrix'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "δεκέμβριο ηνωμένο γεωργιάδης πυροσβεστικής λίνα άγκυρα αγίας πολιτείες διπλωματικό αττικής\n",
      "χαρά μεγάλο κάνουν αυτόν πατρίδα θέση τιμές προφανώς καλή βάση\n",
      "πλέον συνεργασίας είχαν περίπτωση ελληνικής πλευρά σημερινή εντός φυσικό κάποιες\n",
      "είτε κυρίως χωρίς σημείωσε ηνωμένο αναβάθμιση δούμε σύσκεψη διεθνή δυσκολίες\n",
      "γίνεται διότι πάνω στήριξη πρώτο ρόλο γρήγορα αντιμετώπιση λίγο τονίσω\n",
      "δεκέμβριο κυριακή αττικής χρήστο πυροσβεστικής δήμαρχο οικονόμου ηνωμένο αριστοτελία γερμανίας\n",
      "ακόμη μιας εκεί όλων άλλες ευχαριστήσω επιχειρήσεις πρώτα φορές εκτός\n",
      "συνάντησης καλύτερη γίνονται κοινού θέλουμε γαλλίας συζητήσεις μέρους ναυτικού συνέπεια\n",
      "κυριακή γεωργιάδης μπρατάκος διοικητής ευρωζώνη θεόδωρος αριστοτελία πειραιά αττικής δημαρχείο\n",
      "μπορέσουμε σημαντικές έργο έργα συμπολίτες τελευταία λόγω πράγματι ολόκληρη αυτούς\n",
      "επίσκεψη καλύτερο λαού μήνες συνεχίσουμε χρειάζεται διμερείς πορεία λόγω πρωί\n",
      "πάρα αφορούν πρόοδο ευρύτερη ηγέτες έμφαση διμερών ενέργεια θέσει ελληνικές\n",
      "σχέση πατρίδα έκανε ενεργειακή καλά τιμή αύξηση θέμα βάση ασφάλεια\n",
      "ανάγκη αυτήν αγαπητέ μέσω ευρωπαϊκό αυτοί νέες παρεμβάσεις εσείς δικό\n",
      "σημασία περισσότερο περιοχή δική συζήτηση επενδύσεις πρόγραμμα θεωρώ στόχο επόμενο\n",
      "παρά έγινε είχα επειδή λόγο πλήρη ουσιαστικά πλευρά κάποιες μάχη\n",
      "ένας συνάντηση χωρών συζητήσουμε αυτούς ανάπτυξη οικονομία κράτος περαιτέρω μέτρα\n",
      "απόφαση συζητήσουμε νέων κράτη δεκέμβριο ηλεκτρικής καλώς αντιμετωπίζουμε συζητήσαμε χρήστο\n",
      "μεγαλύτερη αυτής προσπάθεια ακριβώς έχετε εμείς γίνουν αερίου προκειμένου απολύτως\n",
      "γεγονός συνέχεια σχετικά εξαιρετικά τελικά θέλουμε ζήτημα αυτοί δυστυχώς τελευταία\n",
      "πρωθυπουργούς γεωργιάδης κυριακή ferreira υπεύθυνος σύντομα γερμανίας ηνωμένο δεκεμβρίου πολεμικής\n",
      "σημαντικά μεγάλες κοινή οικονομική κρίση αυτός αυτού όσον αυτών διάθεσή\n",
      "θέματα απέναντι θέμα αντιμετώπιση ζήτημα μεγάλο εξαιρετικά ασφάλεια εμείς δύσκολη\n",
      "πρόκειται έναρξη βρίσκομαι σχέσεων προστασία ακόλουθη ποτέ προσπάθειες συνάντησή εξελίξεις\n",
      "στήριξης πλήρως γνωρίζετε σχέσεις εξέλιξη κεφαλαίων προχωρήσει διαφορετικά αντιμετωπιστεί σχέδια\n"
     ]
    }
   ],
   "source": [
    "for t in output['topics']:\n",
    "  print(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmi = Coherence(texts=dataset.get_corpus(), topk=5, measure='c_npmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diversity = TopicDiversity(topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic diversity: 0.92\n",
      "Coherence: nan\n"
     ]
    }
   ],
   "source": [
    "topic_diversity_score = topic_diversity.score(output)\n",
    "print(\"Topic diversity: \"+str(topic_diversity_score))\n",
    "\n",
    "npmi_score = npmi.score(output)\n",
    "print(\"Coherence: \"+str(npmi_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpyLDAvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlda_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/pyLDAvis/lda_model.py:94\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(lda_model, dtm, vectorizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create Prepared Data from sklearn's LatentDirichletAllocation and CountVectorizer.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    See `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(\u001b[43m_extract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m)\u001b[49m, kwargs)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pyLDAvis\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/pyLDAvis/lda_model.py:38\u001b[0m, in \u001b[0;36m_extract_data\u001b[0;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_data\u001b[39m(lda_model, dtm, vectorizer):\n\u001b[0;32m---> 38\u001b[0m     vocab \u001b[38;5;241m=\u001b[39m \u001b[43m_get_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     doc_lengths \u001b[38;5;241m=\u001b[39m _get_doc_lengths(dtm)\n\u001b[1;32m     40\u001b[0m     term_freqs \u001b[38;5;241m=\u001b[39m _get_term_freqs(dtm)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/pyLDAvis/lda_model.py:20\u001b[0m, in \u001b[0;36m_get_vocab\u001b[0;34m(vectorizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_vocab\u001b[39m(vectorizer):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "pyLDAvis.lda_model.prepare(model, dataset.get_corpus(), dataset.get_vocabulary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
