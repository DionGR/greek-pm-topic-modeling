{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCTIS Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the performance of most relevant OCTIS models as a baseline for non-SOTA Topic Modeling. These models will be compared on the same preprocessed dataset, the same number of topics and the same evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 01:10:29 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bddcc93a4c24c06924a7a26d98d3258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 01:10:29 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-04 01:10:29 WARNING: Language el package default expects mwt, which has been added\n",
      "2024-04-04 01:10:29 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-04 01:10:29 INFO: Using device: cpu\n",
      "2024-04-04 01:10:29 INFO: Loading: tokenize\n",
      "2024-04-04 01:10:29 INFO: Loading: mwt\n",
      "2024-04-04 01:10:29 INFO: Loading: pos\n",
      "2024-04-04 01:10:30 INFO: Loading: lemma\n",
      "2024-04-04 01:10:30 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from octis.models.LSI import LSI\n",
    "from octis.models.NMF import NMF\n",
    "from octis.models.LDA import LDA\n",
    "from octis.models.HDP import HDP\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.models.ProdLDA import ProdLDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity, KLDivergence\n",
    "from octis.evaluation_metrics.similarity_metrics import RBO, PairwiseJaccardSimilarity\n",
    "from octis.evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "\n",
    "from spacy.lang.el.stop_words import STOP_WORDS as el_stop\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "\n",
    "from utils.data_loader import GreekPMDataloader\n",
    "from models.octis.utils.preprocessor_gr import GreekStanzaPreprocessor\n",
    "from models.octis.config.preprocessing import preprocessor_gr_params\n",
    "from models.octis.config.models import NUM_TOPICS, lsi_params, nmf_params, lda_params, hdp_params, neural_lda_params, prod_lda_params\n",
    "from models.octis.config.optimization import OPTIMIZATION_RESULT_PATH, TOP_K, NUM_PROCESSES, MODEL_RUNS, search_space\n",
    "from models.octis.utils.model_evaluator import OCTISModelEvaluator\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our dataset has already been processed and cached, then we can load it. Otherwise, we will preprocess it and save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found cached - loading...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset = Dataset()\n",
    "    dataset.load_custom_dataset_from_folder('models/octis/data/dataset')\n",
    "    print(\"Dataset found cached - loading...\")\n",
    "except:\n",
    "    print(\"Dataset not found in cache - loading...\")\n",
    "    # Merge data and prepare for preprocessing\n",
    "    try:\n",
    "        speeches_df = pd.read_csv('data/data_speeches.csv')\n",
    "        statements_df = pd.read_csv('data/data_statements.csv')\n",
    "    except: \n",
    "        print(\"GreekPM data not found - fetching...\")\n",
    "        ds = GreekPMDataloader() # If the data is not available, download it\n",
    "        cats_df = ds.load_categories(\"speeches\", \"statements\")\n",
    "        print(\"GreekPM data fetched!\")\n",
    "\n",
    "    df = pd.concat([speeches_df, statements_df], ignore_index=True)\n",
    "    \n",
    "    # Drop irrelevant columns and convert to string\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df = df.drop(columns=['date', 'id', 'url', 'title']).dropna(how='any')\n",
    "    \n",
    "    df.to_csv('data/data_merged.csv', index=False)\n",
    "\n",
    "    # We have some non-Greek stopwords in the dataset, so we need to remove them\n",
    "    stopwords = set(el_stop).union(set(en_stop))\n",
    "    \n",
    "    # Initialize preprocessing\n",
    "    preprocessor = GreekStanzaPreprocessor(\n",
    "                             stopword_list=stopwords, \n",
    "                             **preprocessor_gr_params)\n",
    "    \n",
    "    # Create the dataset\n",
    "    print(\"Preprocessing data...\")\n",
    "    dataset = preprocessor.preprocess_dataset(documents_path='data/data_merged.csv')\n",
    "    \n",
    "    dataset.save('models/octis/data/dataset/')\n",
    "    print(\"Dataset preprocessed and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset.get_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_npmi = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='c_npmi')\n",
    "coherence_cv = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='c_v')\n",
    "coherence_umass = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='u_mass')\n",
    "coherence_uci = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='c_uci')\n",
    "\n",
    "diversity_topic = TopicDiversity(topk=TOP_K)\n",
    "diversity_kl = KLDivergence()\n",
    "\n",
    "similarity_rbo = RBO(topk=TOP_K)\n",
    "similarity_pjs = PairwiseJaccardSimilarity()\n",
    "\n",
    "significance_kluni = KL_uniform()\n",
    "\n",
    "other_metrics = [coherence_npmi, coherence_umass, coherence_uci, diversity_topic, diversity_kl, similarity_rbo, similarity_pjs, significance_kluni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"coherence_npmi\": coherence_npmi, \"coherence_cv\": coherence_cv, \"coherence_umass\": coherence_umass, \"coherence_uci\": coherence_uci, \"diversity_topic\": diversity_topic, \"diversity_kl\": diversity_kl, \"similarity_rbo\": similarity_rbo, \"similarity_pjs\": similarity_pjs, \"significance_kluni\": significance_kluni}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LSI(**lsi_params)\n",
    "lda_model = LDA(**lda_params)\n",
    "hdp_model = HDP(**hdp_params)\n",
    "nmf_model = NMF(**nmf_params)\n",
    "neural_lda_model = NeuralLDA(**neural_lda_params)\n",
    "prod_lda_model = ProdLDA(**prod_lda_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"lsi\": lsi_model, \"lda\": lda_model, \"hdp\": hdp_model, \"nmf\": nmf_model, \"neural_lda\": neural_lda_model, \"prod_lda\": prod_lda_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = OCTISModelEvaluator(dataset=dataset, \n",
    "                                models=models,\n",
    "                                metrics=metrics\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/200]\tSamples: [1439/287800]\tTrain Loss: 3391.998257253301\tTime: 0:00:00.130640\n",
      "Epoch: [1/200]\tSamples: [160/32000]\tValidation Loss: 3077.6486328125\tTime: 0:00:00.005648\n",
      "Epoch: [2/200]\tSamples: [2878/287800]\tTrain Loss: 3308.7821403752605\tTime: 0:00:00.124384\n",
      "Epoch: [2/200]\tSamples: [160/32000]\tValidation Loss: 3073.480224609375\tTime: 0:00:00.005004\n",
      "Epoch: [3/200]\tSamples: [4317/287800]\tTrain Loss: 3271.5446979239055\tTime: 0:00:00.130122\n",
      "Epoch: [3/200]\tSamples: [160/32000]\tValidation Loss: 3067.234423828125\tTime: 0:00:00.006741\n",
      "Epoch: [4/200]\tSamples: [5756/287800]\tTrain Loss: 3240.1369766330786\tTime: 0:00:00.121917\n",
      "Epoch: [4/200]\tSamples: [160/32000]\tValidation Loss: 3056.629052734375\tTime: 0:00:00.008532\n",
      "Epoch: [5/200]\tSamples: [7195/287800]\tTrain Loss: 3223.78409485754\tTime: 0:00:00.132986\n",
      "Epoch: [5/200]\tSamples: [160/32000]\tValidation Loss: 3037.5748046875\tTime: 0:00:00.005372\n",
      "Epoch: [6/200]\tSamples: [8634/287800]\tTrain Loss: 3199.3939313325227\tTime: 0:00:00.133325\n",
      "Epoch: [6/200]\tSamples: [160/32000]\tValidation Loss: 3013.141845703125\tTime: 0:00:00.005982\n",
      "Epoch: [7/200]\tSamples: [10073/287800]\tTrain Loss: 3182.892660919041\tTime: 0:00:00.103917\n",
      "Epoch: [7/200]\tSamples: [160/32000]\tValidation Loss: 2988.78720703125\tTime: 0:00:00.005867\n",
      "Epoch: [8/200]\tSamples: [11512/287800]\tTrain Loss: 3176.733918954135\tTime: 0:00:00.109765\n",
      "Epoch: [8/200]\tSamples: [160/32000]\tValidation Loss: 2971.91181640625\tTime: 0:00:00.004869\n",
      "Epoch: [9/200]\tSamples: [12951/287800]\tTrain Loss: 3161.906347724114\tTime: 0:00:00.109425\n",
      "Epoch: [9/200]\tSamples: [160/32000]\tValidation Loss: 2964.48427734375\tTime: 0:00:00.006839\n",
      "Epoch: [10/200]\tSamples: [14390/287800]\tTrain Loss: 3150.911011335997\tTime: 0:00:00.105508\n",
      "Epoch: [10/200]\tSamples: [160/32000]\tValidation Loss: 2956.11982421875\tTime: 0:00:00.004672\n",
      "Epoch: [11/200]\tSamples: [15829/287800]\tTrain Loss: 3148.5447467859626\tTime: 0:00:00.111918\n",
      "Epoch: [11/200]\tSamples: [160/32000]\tValidation Loss: 2954.902294921875\tTime: 0:00:00.005183\n",
      "Epoch: [12/200]\tSamples: [17268/287800]\tTrain Loss: 3136.5331230455176\tTime: 0:00:00.110223\n",
      "Epoch: [12/200]\tSamples: [160/32000]\tValidation Loss: 2946.421142578125\tTime: 0:00:00.006254\n",
      "Epoch: [13/200]\tSamples: [18707/287800]\tTrain Loss: 3133.9696295170256\tTime: 0:00:00.108904\n",
      "Epoch: [13/200]\tSamples: [160/32000]\tValidation Loss: 2947.38076171875\tTime: 0:00:00.004678\n",
      "Epoch: [14/200]\tSamples: [20146/287800]\tTrain Loss: 3122.8757329308546\tTime: 0:00:00.103654\n",
      "Epoch: [14/200]\tSamples: [160/32000]\tValidation Loss: 2938.08447265625\tTime: 0:00:00.006148\n",
      "Epoch: [15/200]\tSamples: [21585/287800]\tTrain Loss: 3114.563661831133\tTime: 0:00:00.115308\n",
      "Epoch: [15/200]\tSamples: [160/32000]\tValidation Loss: 2935.258544921875\tTime: 0:00:00.004322\n",
      "Epoch: [16/200]\tSamples: [23024/287800]\tTrain Loss: 3108.7764723766504\tTime: 0:00:00.114344\n",
      "Epoch: [16/200]\tSamples: [160/32000]\tValidation Loss: 2932.55810546875\tTime: 0:00:00.004767\n",
      "Epoch: [17/200]\tSamples: [24463/287800]\tTrain Loss: 3099.8967653318277\tTime: 0:00:00.112517\n",
      "Epoch: [17/200]\tSamples: [160/32000]\tValidation Loss: 2934.045947265625\tTime: 0:00:00.005967\n",
      "Epoch: [18/200]\tSamples: [25902/287800]\tTrain Loss: 3095.719814107019\tTime: 0:00:00.105419\n",
      "Epoch: [18/200]\tSamples: [160/32000]\tValidation Loss: 2928.63994140625\tTime: 0:00:00.006162\n",
      "Epoch: [19/200]\tSamples: [27341/287800]\tTrain Loss: 3092.700296429812\tTime: 0:00:00.118100\n",
      "Epoch: [19/200]\tSamples: [160/32000]\tValidation Loss: 2922.7890625\tTime: 0:00:00.007717\n",
      "Epoch: [20/200]\tSamples: [28780/287800]\tTrain Loss: 3092.5296212647672\tTime: 0:00:00.107975\n",
      "Epoch: [20/200]\tSamples: [160/32000]\tValidation Loss: 2920.851025390625\tTime: 0:00:00.005655\n",
      "Epoch: [21/200]\tSamples: [30219/287800]\tTrain Loss: 3085.1674068363445\tTime: 0:00:00.096576\n",
      "Epoch: [21/200]\tSamples: [160/32000]\tValidation Loss: 2920.6884521484376\tTime: 0:00:00.010737\n",
      "Epoch: [22/200]\tSamples: [31658/287800]\tTrain Loss: 3080.837175338777\tTime: 0:00:00.110523\n",
      "Epoch: [22/200]\tSamples: [160/32000]\tValidation Loss: 2912.0115234375\tTime: 0:00:00.004389\n",
      "Epoch: [23/200]\tSamples: [33097/287800]\tTrain Loss: 3072.0471138811677\tTime: 0:00:00.102585\n",
      "Epoch: [23/200]\tSamples: [160/32000]\tValidation Loss: 2910.435595703125\tTime: 0:00:00.004949\n",
      "Epoch: [24/200]\tSamples: [34536/287800]\tTrain Loss: 3070.077902406185\tTime: 0:00:00.105711\n",
      "Epoch: [24/200]\tSamples: [160/32000]\tValidation Loss: 2904.47548828125\tTime: 0:00:00.004373\n",
      "Epoch: [25/200]\tSamples: [35975/287800]\tTrain Loss: 3073.7948553683113\tTime: 0:00:00.107024\n",
      "Epoch: [25/200]\tSamples: [160/32000]\tValidation Loss: 2905.1814453125\tTime: 0:00:00.004846\n",
      "Epoch: [26/200]\tSamples: [37414/287800]\tTrain Loss: 3077.678254212995\tTime: 0:00:00.105127\n",
      "Epoch: [26/200]\tSamples: [160/32000]\tValidation Loss: 2899.9103515625\tTime: 0:00:00.006516\n",
      "Epoch: [27/200]\tSamples: [38853/287800]\tTrain Loss: 3069.8051109711605\tTime: 0:00:00.102469\n",
      "Epoch: [27/200]\tSamples: [160/32000]\tValidation Loss: 2901.83095703125\tTime: 0:00:00.004922\n",
      "Epoch: [28/200]\tSamples: [40292/287800]\tTrain Loss: 3064.4127215079916\tTime: 0:00:00.113898\n",
      "Epoch: [28/200]\tSamples: [160/32000]\tValidation Loss: 2905.643603515625\tTime: 0:00:00.005187\n",
      "Epoch: [29/200]\tSamples: [41731/287800]\tTrain Loss: 3066.1324596073664\tTime: 0:00:00.110822\n",
      "Epoch: [29/200]\tSamples: [160/32000]\tValidation Loss: 2900.75107421875\tTime: 0:00:00.006823\n",
      "Epoch: [30/200]\tSamples: [43170/287800]\tTrain Loss: 3058.653882904795\tTime: 0:00:00.102916\n",
      "Epoch: [30/200]\tSamples: [160/32000]\tValidation Loss: 2896.788037109375\tTime: 0:00:00.006409\n",
      "Epoch: [31/200]\tSamples: [44609/287800]\tTrain Loss: 3064.8990835649756\tTime: 0:00:00.103194\n",
      "Epoch: [31/200]\tSamples: [160/32000]\tValidation Loss: 2899.515234375\tTime: 0:00:00.006305\n",
      "Epoch: [32/200]\tSamples: [46048/287800]\tTrain Loss: 3059.561273019458\tTime: 0:00:00.107470\n",
      "Epoch: [32/200]\tSamples: [160/32000]\tValidation Loss: 2895.39716796875\tTime: 0:00:00.004784\n",
      "Epoch: [33/200]\tSamples: [47487/287800]\tTrain Loss: 3052.6409317451357\tTime: 0:00:00.102506\n",
      "Epoch: [33/200]\tSamples: [160/32000]\tValidation Loss: 2897.537939453125\tTime: 0:00:00.005229\n",
      "Epoch: [34/200]\tSamples: [48926/287800]\tTrain Loss: 3055.553634251216\tTime: 0:00:00.108086\n",
      "Epoch: [34/200]\tSamples: [160/32000]\tValidation Loss: 2896.264794921875\tTime: 0:00:00.006755\n",
      "Epoch: [35/200]\tSamples: [50365/287800]\tTrain Loss: 3054.380298818624\tTime: 0:00:00.105340\n",
      "Epoch: [35/200]\tSamples: [160/32000]\tValidation Loss: 2894.5849609375\tTime: 0:00:00.004837\n",
      "Epoch: [36/200]\tSamples: [51804/287800]\tTrain Loss: 3050.512693276581\tTime: 0:00:00.108213\n",
      "Epoch: [36/200]\tSamples: [160/32000]\tValidation Loss: 2887.88701171875\tTime: 0:00:00.005220\n",
      "Epoch: [37/200]\tSamples: [53243/287800]\tTrain Loss: 3090.085476025017\tTime: 0:00:00.108227\n",
      "Epoch: [37/200]\tSamples: [160/32000]\tValidation Loss: 2894.12666015625\tTime: 0:00:00.005115\n",
      "Epoch: [38/200]\tSamples: [54682/287800]\tTrain Loss: 3056.3494234277277\tTime: 0:00:00.108290\n",
      "Epoch: [38/200]\tSamples: [160/32000]\tValidation Loss: 2888.386474609375\tTime: 0:00:00.006820\n",
      "Epoch: [39/200]\tSamples: [56121/287800]\tTrain Loss: 3058.4235091643504\tTime: 0:00:00.105944\n",
      "Epoch: [39/200]\tSamples: [160/32000]\tValidation Loss: 2888.8859375\tTime: 0:00:00.004870\n",
      "Epoch: [40/200]\tSamples: [57560/287800]\tTrain Loss: 3050.979472506949\tTime: 0:00:00.103731\n",
      "Epoch: [40/200]\tSamples: [160/32000]\tValidation Loss: 2891.47900390625\tTime: 0:00:00.005157\n",
      "Epoch: [41/200]\tSamples: [58999/287800]\tTrain Loss: 3051.185670387422\tTime: 0:00:00.107709\n",
      "Epoch: [41/200]\tSamples: [160/32000]\tValidation Loss: 2888.930859375\tTime: 0:00:00.004876\n",
      "Early stopping\n",
      "Epoch: [1/50]\tSamples: [1439/71950]\tTrain Loss: 3513.2719119179988\tTime: 0:00:00.088768\n",
      "Epoch: [1/50]\tSamples: [160/8000]\tValidation Loss: 7241591.367382812\tTime: 0:00:00.008243\n",
      "Epoch: [2/50]\tSamples: [2878/71950]\tTrain Loss: 3353.7735677988185\tTime: 0:00:00.091523\n",
      "Epoch: [2/50]\tSamples: [160/8000]\tValidation Loss: 3213.701171875\tTime: 0:00:00.004971\n",
      "Epoch: [3/50]\tSamples: [4317/71950]\tTrain Loss: 3264.784626911049\tTime: 0:00:00.092743\n",
      "Epoch: [3/50]\tSamples: [160/8000]\tValidation Loss: 3096.31826171875\tTime: 0:00:00.005548\n",
      "Epoch: [4/50]\tSamples: [5756/71950]\tTrain Loss: 3217.885510771369\tTime: 0:00:00.090300\n",
      "Epoch: [4/50]\tSamples: [160/8000]\tValidation Loss: 3209.1962890625\tTime: 0:00:00.005194\n",
      "Epoch: [5/50]\tSamples: [7195/71950]\tTrain Loss: 3216.048655750521\tTime: 0:00:00.087435\n",
      "Epoch: [5/50]\tSamples: [160/8000]\tValidation Loss: 3076.441796875\tTime: 0:00:00.003983\n",
      "Epoch: [6/50]\tSamples: [8634/71950]\tTrain Loss: 3240.7426598332177\tTime: 0:00:00.088474\n",
      "Epoch: [6/50]\tSamples: [160/8000]\tValidation Loss: 3034.1158203125\tTime: 0:00:00.005086\n",
      "Epoch: [7/50]\tSamples: [10073/71950]\tTrain Loss: 3262.3974005385685\tTime: 0:00:00.095133\n",
      "Epoch: [7/50]\tSamples: [160/8000]\tValidation Loss: 61996.14692382813\tTime: 0:00:00.004760\n",
      "Epoch: [8/50]\tSamples: [11512/71950]\tTrain Loss: 3204.4933221855454\tTime: 0:00:00.082685\n",
      "Epoch: [8/50]\tSamples: [160/8000]\tValidation Loss: 12928.217529296875\tTime: 0:00:00.004032\n",
      "Epoch: [9/50]\tSamples: [12951/71950]\tTrain Loss: 3195.1605987230714\tTime: 0:00:00.090456\n",
      "Epoch: [9/50]\tSamples: [160/8000]\tValidation Loss: 3278.086669921875\tTime: 0:00:00.004009\n",
      "Epoch: [10/50]\tSamples: [14390/71950]\tTrain Loss: 3177.0754321577483\tTime: 0:00:00.096632\n",
      "Epoch: [10/50]\tSamples: [160/8000]\tValidation Loss: 3086.081103515625\tTime: 0:00:00.003874\n",
      "Epoch: [11/50]\tSamples: [15829/71950]\tTrain Loss: 3156.8606481280403\tTime: 0:00:00.097273\n",
      "Epoch: [11/50]\tSamples: [160/8000]\tValidation Loss: 3070.401953125\tTime: 0:00:00.005349\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dion/Library/CloudStorage/GoogleDrive-dion.rigatos@gmail.com/My Drive/Archivio/University/Classes/Erasmus Courses/NLP/NLP Project/greek-pm-topic-modeling/src/models/octis/utils/model_evaluator.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.evaluation_df = pd.concat([self.evaluation_df, pd.DataFrame({\n",
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/octis/evaluation_metrics/diversity_metrics.py:244: RuntimeWarning: invalid value encountered in log\n",
      "  divergence = np.sum(P*np.log(P/Q))\n",
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/octis/evaluation_metrics/topic_significance_metrics.py:24: RuntimeWarning: invalid value encountered in log\n",
      "  divergence = np.sum(P*np.log(P/Q))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>coherence_npmi</td>\n",
       "      <td>0.134213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>coherence_cv</td>\n",
       "      <td>0.676730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>coherence_umass</td>\n",
       "      <td>-1.339673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>coherence_uci</td>\n",
       "      <td>0.438398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>diversity_topic</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>diversity_kl</td>\n",
       "      <td>0.884909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>similarity_rbo</td>\n",
       "      <td>0.056343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>similarity_pjs</td>\n",
       "      <td>0.038630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>significance_kluni</td>\n",
       "      <td>0.434979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>coherence_npmi</td>\n",
       "      <td>0.100865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>coherence_cv</td>\n",
       "      <td>0.667727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>coherence_umass</td>\n",
       "      <td>-1.127919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>coherence_uci</td>\n",
       "      <td>0.251517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>diversity_topic</td>\n",
       "      <td>0.876923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>diversity_kl</td>\n",
       "      <td>2.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>similarity_rbo</td>\n",
       "      <td>0.018860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>similarity_pjs</td>\n",
       "      <td>0.015034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lda</td>\n",
       "      <td>significance_kluni</td>\n",
       "      <td>1.314428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>coherence_npmi</td>\n",
       "      <td>-0.038970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>coherence_cv</td>\n",
       "      <td>0.518382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>coherence_umass</td>\n",
       "      <td>-2.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>coherence_uci</td>\n",
       "      <td>-2.399923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>diversity_topic</td>\n",
       "      <td>0.561333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>diversity_kl</td>\n",
       "      <td>0.356169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>similarity_rbo</td>\n",
       "      <td>0.016843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>similarity_pjs</td>\n",
       "      <td>0.013833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hdp</td>\n",
       "      <td>significance_kluni</td>\n",
       "      <td>0.211211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>coherence_npmi</td>\n",
       "      <td>0.200759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>coherence_cv</td>\n",
       "      <td>0.740798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>coherence_umass</td>\n",
       "      <td>-1.049820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>coherence_uci</td>\n",
       "      <td>1.135089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>diversity_topic</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>diversity_kl</td>\n",
       "      <td>3.867234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>similarity_rbo</td>\n",
       "      <td>0.073548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>similarity_pjs</td>\n",
       "      <td>0.078268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nmf</td>\n",
       "      <td>significance_kluni</td>\n",
       "      <td>2.120964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>coherence_npmi</td>\n",
       "      <td>0.005012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>coherence_cv</td>\n",
       "      <td>0.585870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>coherence_umass</td>\n",
       "      <td>-1.536813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>coherence_uci</td>\n",
       "      <td>-1.351965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>diversity_topic</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>diversity_kl</td>\n",
       "      <td>0.864379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>similarity_rbo</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>similarity_pjs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>significance_kluni</td>\n",
       "      <td>0.484267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>coherence_npmi</td>\n",
       "      <td>-0.120499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>coherence_cv</td>\n",
       "      <td>0.535190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>coherence_umass</td>\n",
       "      <td>-2.942232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>coherence_uci</td>\n",
       "      <td>-5.237141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>diversity_topic</td>\n",
       "      <td>0.876923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>diversity_kl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>similarity_rbo</td>\n",
       "      <td>0.015429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>similarity_pjs</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>significance_kluni</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model              metric     value\n",
       "0         lsi      coherence_npmi  0.134213\n",
       "0         lsi        coherence_cv  0.676730\n",
       "0         lsi     coherence_umass -1.339673\n",
       "0         lsi       coherence_uci  0.438398\n",
       "0         lsi     diversity_topic  0.738462\n",
       "0         lsi        diversity_kl  0.884909\n",
       "0         lsi      similarity_rbo  0.056343\n",
       "0         lsi      similarity_pjs  0.038630\n",
       "0         lsi  significance_kluni  0.434979\n",
       "0         lda      coherence_npmi  0.100865\n",
       "0         lda        coherence_cv  0.667727\n",
       "0         lda     coherence_umass -1.127919\n",
       "0         lda       coherence_uci  0.251517\n",
       "0         lda     diversity_topic  0.876923\n",
       "0         lda        diversity_kl  2.097100\n",
       "0         lda      similarity_rbo  0.018860\n",
       "0         lda      similarity_pjs  0.015034\n",
       "0         lda  significance_kluni  1.314428\n",
       "0         hdp      coherence_npmi -0.038970\n",
       "0         hdp        coherence_cv  0.518382\n",
       "0         hdp     coherence_umass -2.151200\n",
       "0         hdp       coherence_uci -2.399923\n",
       "0         hdp     diversity_topic  0.561333\n",
       "0         hdp        diversity_kl  0.356169\n",
       "0         hdp      similarity_rbo  0.016843\n",
       "0         hdp      similarity_pjs  0.013833\n",
       "0         hdp  significance_kluni  0.211211\n",
       "0         nmf      coherence_npmi  0.200759\n",
       "0         nmf        coherence_cv  0.740798\n",
       "0         nmf     coherence_umass -1.049820\n",
       "0         nmf       coherence_uci  1.135089\n",
       "0         nmf     diversity_topic  0.661538\n",
       "0         nmf        diversity_kl  3.867234\n",
       "0         nmf      similarity_rbo  0.073548\n",
       "0         nmf      similarity_pjs  0.078268\n",
       "0         nmf  significance_kluni  2.120964\n",
       "0  neural_lda      coherence_npmi  0.005012\n",
       "0  neural_lda        coherence_cv  0.585870\n",
       "0  neural_lda     coherence_umass -1.536813\n",
       "0  neural_lda       coherence_uci -1.351965\n",
       "0  neural_lda     diversity_topic  1.000000\n",
       "0  neural_lda        diversity_kl  0.864379\n",
       "0  neural_lda      similarity_rbo  0.000000\n",
       "0  neural_lda      similarity_pjs  0.000000\n",
       "0  neural_lda  significance_kluni  0.484267\n",
       "0    prod_lda      coherence_npmi -0.120499\n",
       "0    prod_lda        coherence_cv  0.535190\n",
       "0    prod_lda     coherence_umass -2.942232\n",
       "0    prod_lda       coherence_uci -5.237141\n",
       "0    prod_lda     diversity_topic  0.876923\n",
       "0    prod_lda        diversity_kl       NaN\n",
       "0    prod_lda      similarity_rbo  0.015429\n",
       "0    prod_lda      similarity_pjs  0.008485\n",
       "0    prod_lda  significance_kluni       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
