{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCTIS Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the performance of most relevant OCTIS models as a baseline for non-SOTA Topic Modeling. These models will be compared on the same preprocessed dataset, the same number of topics and the same evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 15:27:25 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfac2473426b4a35bb9f0ef78334cab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 15:27:25 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-03 15:27:25 WARNING: Language el package default expects mwt, which has been added\n",
      "2024-04-03 15:27:25 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-03 15:27:25 INFO: Using device: cpu\n",
      "2024-04-03 15:27:25 INFO: Loading: tokenize\n",
      "2024-04-03 15:27:26 INFO: Loading: mwt\n",
      "2024-04-03 15:27:26 INFO: Loading: pos\n",
      "2024-04-03 15:27:26 INFO: Loading: lemma\n",
      "2024-04-03 15:27:26 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from octis.models import LSI, NMF, LDA, HDP, NeuralLDA, ProdLDA, ETM\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "\n",
    "from spacy.lang.el.stop_words import STOP_WORDS as el_stop\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "\n",
    "from utils.data_loader import GreekPMDataloader\n",
    "from models.octis.utils.preprocessor_gr import GreekStanzaPreprocessor\n",
    "from models.octis.config.preprocessing import preprocessor_gr_params\n",
    "from models.octis.config.models import NUM_TOPICS, lsi_params, nmf_params, lda_params, hdp_params, neural_lda_params, prod_lda_params, etm_params\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our dataset has already been processed and cached, then we can load it. Otherwise, we will preprocess it and save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found cached - loading...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset = Dataset()\n",
    "    dataset.load_custom_dataset_from_folder('models/octis/data/dataset')\n",
    "    print(\"Dataset found cached - loading...\")\n",
    "except:\n",
    "    print(\"Dataset not found in cache - loading...\")\n",
    "    # Merge data and prepare for preprocessing\n",
    "    try:\n",
    "        speeches_df = pd.read_csv('data/data_speeches.csv')\n",
    "        statements_df = pd.read_csv('data/data_statements.csv')\n",
    "    except: \n",
    "        print(\"GreekPM data not found - fetching...\")\n",
    "        ds = GreekPMDataloader() # If the data is not available, download it\n",
    "        cats_df = ds.load_categories(\"speeches\", \"statements\")\n",
    "        print(\"GreekPM data fetched!\")\n",
    "\n",
    "    df = pd.concat([speeches_df, statements_df], ignore_index=True)\n",
    "    \n",
    "    # Drop irrelevant columns and convert to string\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    df = df.drop(columns=['date', 'id', 'url', 'title']).dropna(how='any')\n",
    "    \n",
    "    df.to_csv('data/data_merged.csv', index=False)\n",
    "\n",
    "    # We have some non-Greek stopwords in the dataset, so we need to remove them\n",
    "    stopwords = set(el_stop).union(set(en_stop))\n",
    "    \n",
    "    # Initialize preprocessing\n",
    "    preprocessor = GreekStanzaPreprocessor(\n",
    "                             stopword_list=stopwords, \n",
    "                             **preprocessor_gr_params)\n",
    "    \n",
    "    # Create the dataset\n",
    "    print(\"Preprocessing data...\")\n",
    "    dataset = preprocessor.preprocess_dataset(documents_path='data/data_merged.csv')\n",
    "    \n",
    "    dataset.save('models/octis/data/dataset/')\n",
    "    print(\"Dataset preprocessed and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence_npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_npmi')\n",
    "# coherence_cv = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_v')\n",
    "# coherence_umass = Coherence(texts=dataset.get_corpus(), topk=10, measure='u_mass')\n",
    "# coherence_uci = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_uci')\n",
    "# topic_diversity = TopicDiversity(topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LSI.LSI(num_topics=NUM_TOPICS, **lsi_params)\n",
    "# lda_model = LDA(num_topics=NUM_TOPICS, dataset=dataset, **lda_params)\n",
    "# hdp_model = HDP(num_topics=NUM_TOPICS, dataset=dataset, **hdp_params)\n",
    "# nmf_model = NMF(num_topics=NUM_TOPICS, dataset=dataset, **nmf_params)\n",
    "# neural_lda_model = NeuralLDA(num_topics=NUM_TOPICS, dataset=dataset, **neural_lda_params)\n",
    "# prod_lda_model = ProdLDA(num_topics=NUM_TOPICS, dataset=dataset, **prod_lda_params)\n",
    "# etm_model = ETM(num_topics=NUM_TOPICS, dataset=dataset, **etm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in output['topics']:\n",
    "  print(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmi = Coherence(texts=dataset.get_corpus(), topk=5, measure='c_npmi')\n",
    "cv = Coherence(texts=dataset.get_corpus(), topk=5, measure='c_v')\n",
    "umass = Coherence(texts=dataset.get_corpus(), topk=5, measure='u_mass')\n",
    "uci = Coherence(texts=dataset.get_corpus(), topk=5, measure='c_uci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diversity = TopicDiversity(topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diversity_score = topic_diversity.score(output)\n",
    "print(\"Topic diversity: \"+str(topic_diversity_score))\n",
    "\n",
    "npmi_score = npmi.score(output)\n",
    "print(\"NPMI Coherence: \"+str(npmi_score)) \n",
    "\n",
    "cv_score = cv.score(output)\n",
    "print(\"C_V Coherence: \"+str(cv_score))\n",
    "\n",
    "umass_score = umass.score(output)\n",
    "print(\"U_MASS Coherence: \"+str(umass_score))\n",
    "\n",
    "uci_score = uci.score(output)\n",
    "print(\"C_UCI Coherence: \"+str(uci_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
