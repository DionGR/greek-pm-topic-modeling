{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.models.LDA import LDA\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "\n",
    "from spacy.lang.el.stop_words import STOP_WORDS as el_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df = pd.read_csv('data/data_speeches.csv')\n",
    "statements_df = pd.read_csv('data/data_statements.csv')\n",
    "\n",
    "# merge the two datasets\n",
    "df = pd.concat([speeches_df, statements_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>32458</td>\n",
       "      <td>https://www.primeminister.gr/2023/09/04/32458</td>\n",
       "      <td>Δήλωση του Πρωθυπουργού Κυριάκου Μητσοτάκη μετ...</td>\n",
       "      <td>Ευχαριστώ Νίκο και Bibi, ευχαριστώ καταρχάς γι...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>26759</td>\n",
       "      <td>https://www.primeminister.gr/2021/06/16/26759</td>\n",
       "      <td>Δευτερολογία και τριτολογία του Πρωθυπουργού Κ...</td>\n",
       "      <td>Κύριε Τσίπρα, βρήκα πολύ ενδιαφέρουσα την ιστο...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>27456</td>\n",
       "      <td>https://www.primeminister.gr/2021/09/17/27456</td>\n",
       "      <td>Δήλωση του Πρωθυπουργού Κυριάκου Μητσοτάκη πρι...</td>\n",
       "      <td>Κυρίες και κύριοι, Με μεγάλη μου χαρά καλωσορί...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>20837</td>\n",
       "      <td>https://www.primeminister.gr/2018/11/22/20837</td>\n",
       "      <td>“Το δικό μας μνημόνιο είναι με τον ελληνικό λα...</td>\n",
       "      <td>Παρέμβαση στη Βουλή κατά τη συζήτηση του νομοσ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>31735</td>\n",
       "      <td>https://www.primeminister.gr/2023/04/22/31735</td>\n",
       "      <td>Δηλώσεις της Προέδρου της Δημοκρατίας Κατερίνα...</td>\n",
       "      <td>Κυριάκος Μητσοτάκης: Κυρία Πρόεδρε, έχω την χα...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     id                                            url  \\\n",
       "743   2023-09-04  32458  https://www.primeminister.gr/2023/09/04/32458   \n",
       "276   2021-06-16  26759  https://www.primeminister.gr/2021/06/16/26759   \n",
       "1003  2021-09-17  27456  https://www.primeminister.gr/2021/09/17/27456   \n",
       "482   2018-11-22  20837  https://www.primeminister.gr/2018/11/22/20837   \n",
       "779   2023-04-22  31735  https://www.primeminister.gr/2023/04/22/31735   \n",
       "\n",
       "                                                  title  \\\n",
       "743   Δήλωση του Πρωθυπουργού Κυριάκου Μητσοτάκη μετ...   \n",
       "276   Δευτερολογία και τριτολογία του Πρωθυπουργού Κ...   \n",
       "1003  Δήλωση του Πρωθυπουργού Κυριάκου Μητσοτάκη πρι...   \n",
       "482   “Το δικό μας μνημόνιο είναι με τον ελληνικό λα...   \n",
       "779   Δηλώσεις της Προέδρου της Δημοκρατίας Κατερίνα...   \n",
       "\n",
       "                                                   text  \n",
       "743   Ευχαριστώ Νίκο και Bibi, ευχαριστώ καταρχάς γι...  \n",
       "276   Κύριε Τσίπρα, βρήκα πολύ ενδιαφέρουσα την ιστο...  \n",
       "1003  Κυρίες και κύριοι, Με μεγάλη μου χαρά καλωσορί...  \n",
       "482   Παρέμβαση στη Βουλή κατά τη συζήτηση του νομοσ...  \n",
       "779   Κυριάκος Μητσοτάκης: Κυρία Πρόεδρε, έχω την χα...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Από τις Βρυξέλλες όπου βρίσκομαι για τη Σύνοδο...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Κυριάκος Μητσοτάκης: Καθώς μπαίνουμε πια στον ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Κυρίες και κύριοι, εκπρόσωποι της Τοπικής Αυ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>Ο Πρωθυπουργός Κυριάκος Μητσοτάκης παραβρέθηκε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Είχαμε μία παραγωγική συζήτηση με τον Πρόεδρο ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "763  Από τις Βρυξέλλες όπου βρίσκομαι για τη Σύνοδο...\n",
       "816  Κυριάκος Μητσοτάκης: Καθώς μπαίνουμε πια στον ...\n",
       "634    Κυρίες και κύριοι, εκπρόσωποι της Τοπικής Αυ...\n",
       "928  Ο Πρωθυπουργός Κυριάκος Μητσοτάκης παραβρέθηκε...\n",
       "732  Είχαμε μία παραγωγική συζήτηση με τον Πρόεδρο ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop date, id, url, title \n",
    "df = df.drop(columns=['date', 'id', 'url', 'title'])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the merged dataset\n",
    "df.to_csv('data/data_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7080c5087ca44810824882da0156ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "4253\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "# Initialize preprocessing\n",
    "preprocessor = Preprocessing(vocabulary=None, language='greek', \n",
    "                             remove_stopwords_spacy=True,\n",
    "                             lemmatize=True, lowercase=True, \n",
    "                             punctuation=string.punctuation, remove_punctuation=True, remove_numbers=True,\n",
    "                             max_df=0.4, min_df=0.01, min_chars=4,  min_words_docs=20, \n",
    "                             verbose=True, num_processes=8)\n",
    "# preprocess\n",
    "dataset = preprocessor.preprocess_dataset(documents_path='data/data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "dataset.save('data/data_merged_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic-word-matrix\n",
      "topics\n",
      "topic-document-matrix\n",
      "test-topic-document-matrix\n"
     ]
    }
   ],
   "source": [
    "model = LDA(num_topics=10, chunksize=32, alpha=\"symmetric\",  passes=100)\n",
    "\n",
    "output = model.train_model(dataset)\n",
    "\n",
    "print(*list(output.keys()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['topic-word-matrix', 'topics', 'topic-document-matrix', 'test-topic-document-matrix'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "έργα έργο οποίο στον έχουν μεγάλη σημαντικό σήμερα ώστε καθώς\n",
      "έχουν πρέπει οποίο όπως μόνο κάθε μπορεί σήμερα τελικά στους\n",
      "ολοκλήρωση επένδυση σημαντική στον νέες υψηλής εκπαίδευση εταιρείες παιδιά νέων\n",
      "θέμα πολιτικό ζήτημα συζήτηση θυμίσω προς θέματα εξωτερική πολιτικού στάση\n",
      "στις κάθε στον σήμερα όπως χώρα όλες πάντα όλους απέναντι\n",
      "στις χώρα ευρώ επιχειρήσεις οικονομία προς όπως κατά ανάπτυξη μείωση\n",
      "ήταν εσείς γιατί αυτά όταν κύριε έχετε ούτε αυτήν διότι\n",
      "έχουμε οποίο πρέπει κάνουμε μπορούμε οποίες ήταν μπορεί είμαστε νομίζω\n",
      "πρέπει χώρες στις αφορά επίσης μεταξύ όπως έχουμε συνεργασία προς\n",
      "χρόνια έχουμε χώρα πρέπει ήταν μετά μέσα στις έχουν μπορεί\n"
     ]
    }
   ],
   "source": [
    "for t in output['topics']:\n",
    "  print(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmi = Coherence(texts=dataset.get_corpus(), topk=5, measure='c_npmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_diversity = TopicDiversity(topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic diversity: 0.72\n",
      "Coherence: 0.020386687524211588\n"
     ]
    }
   ],
   "source": [
    "topic_diversity_score = topic_diversity.score(output)\n",
    "print(\"Topic diversity: \"+str(topic_diversity_score))\n",
    "\n",
    "npmi_score = npmi.score(output)\n",
    "print(\"Coherence: \"+str(npmi_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpyLDAvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlda_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/pyLDAvis/lda_model.py:94\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare\u001b[39m(lda_model, dtm, vectorizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create Prepared Data from sklearn's LatentDirichletAllocation and CountVectorizer.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    See `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(\u001b[43m_extract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlda_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m)\u001b[49m, kwargs)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pyLDAvis\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/pyLDAvis/lda_model.py:38\u001b[0m, in \u001b[0;36m_extract_data\u001b[0;34m(lda_model, dtm, vectorizer)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_data\u001b[39m(lda_model, dtm, vectorizer):\n\u001b[0;32m---> 38\u001b[0m     vocab \u001b[38;5;241m=\u001b[39m \u001b[43m_get_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     doc_lengths \u001b[38;5;241m=\u001b[39m _get_doc_lengths(dtm)\n\u001b[1;32m     40\u001b[0m     term_freqs \u001b[38;5;241m=\u001b[39m _get_term_freqs(dtm)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/pyLDAvis/lda_model.py:20\u001b[0m, in \u001b[0;36m_get_vocab\u001b[0;34m(vectorizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_vocab\u001b[39m(vectorizer):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "pyLDAvis.lda_model.prepare(model, dataset.get_corpus(), dataset.get_vocabulary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
