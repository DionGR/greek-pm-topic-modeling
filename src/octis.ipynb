{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCTIS Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the performance of most relevant OCTIS models as a baseline for non-SOTA Topic Modeling. These models will be compared on the same preprocessed dataset, the same number of topics and the same evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 18:40:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17297ebcc00e4e82888f4e848a0add69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 18:40:14 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-06 18:40:14 WARNING: Language el package default expects mwt, which has been added\n",
      "2024-04-06 18:40:14 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:14 INFO: Using device: cpu\n",
      "2024-04-06 18:40:14 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:15 INFO: Loading: mwt\n",
      "2024-04-06 18:40:15 INFO: Loading: pos\n",
      "2024-04-06 18:40:15 INFO: Loading: lemma\n",
      "2024-04-06 18:40:15 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from octis.models.LSI import LSI\n",
    "from octis.models.NMF import NMF\n",
    "from octis.models.LDA import LDA\n",
    "from octis.models.HDP import HDP\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.models.ProdLDA import ProdLDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity, KLDivergence\n",
    "from octis.evaluation_metrics.similarity_metrics import RBO, PairwiseJaccardSimilarity\n",
    "from octis.evaluation_metrics.topic_significance_metrics import KL_uniform\n",
    "\n",
    "from spacy.lang.el.stop_words import STOP_WORDS as el_stop\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "\n",
    "from utils.data_loader import GreekPMDataloader\n",
    "from models.octis.utils.preprocessor_gr import GreekStanzaPreprocessor\n",
    "from models.octis.config.preprocessing import preprocessor_gr_params\n",
    "from models.octis.config.models import NUM_TOPICS, lsi_params, nmf_params, lda_params, hdp_params, neural_lda_params, prod_lda_params\n",
    "from models.octis.config.optimization import OPTIMIZATION_RESULT_PATH, TOP_K, NUM_PROCESSES, MODEL_RUNS, search_space\n",
    "from models.octis.utils.model_evaluator import OCTISModelEvaluator\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has already been preprocessed in the `analysis` notebook, so we will load it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found in cache - loading...\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9073288f457451a90c4caacb52e377f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 18:40:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2024-04-06 18:40:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2024-04-06 18:40:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2024-04-06 18:40:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2024-04-06 18:40:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "2024-04-06 18:40:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.0MB/s]                    \n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 16.9MB/s]                    \n",
      "2024-04-06 18:40:19 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-06 18:40:19 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|          | 0.00/47.2k [00:00<?, ?B/s]2024-04-06 18:40:19 WARNING: Language el package default expects mwt, which has been added\n",
      "2024-04-06 18:40:19 WARNING: Language el package default expects mwt, which has been added\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.7MB/s]                    \n",
      "2024-04-06 18:40:19 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-06 18:40:19 WARNING: Language el package default expects mwt, which has been added\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.2MB/s]                    \n",
      "2024-04-06 18:40:19 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-06 18:40:19 WARNING: Language el package default expects mwt, which has been added\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 15.4MB/s]                    \n",
      "2024-04-06 18:40:19 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-06 18:40:19 WARNING: Language el package default expects mwt, which has been added\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 18.7MB/s]                    \n",
      "2024-04-06 18:40:19 INFO: Downloaded file to /Users/dion/stanza_resources/resources.json\n",
      "2024-04-06 18:40:19 WARNING: Language el package default expects mwt, which has been added\n",
      "2024-04-06 18:40:19 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:19 INFO: Using device: cpu\n",
      "2024-04-06 18:40:19 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:19 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:19 INFO: Using device: cpu\n",
      "2024-04-06 18:40:19 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:19 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:19 INFO: Using device: cpu\n",
      "2024-04-06 18:40:19 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:19 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:19 INFO: Using device: cpu\n",
      "2024-04-06 18:40:19 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:19 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:19 INFO: Using device: cpu\n",
      "2024-04-06 18:40:19 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:19 INFO: Loading these models for language: el (Greek):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | gdt                     |\n",
      "| mwt       | gdt                     |\n",
      "| pos       | models/oct..._tagger.pt |\n",
      "| lemma     | models/oct...matizer.pt |\n",
      "=======================================\n",
      "\n",
      "2024-04-06 18:40:19 INFO: Using device: cpu\n",
      "2024-04-06 18:40:19 INFO: Loading: tokenize\n",
      "2024-04-06 18:40:19 INFO: Loading: mwt\n",
      "2024-04-06 18:40:19 INFO: Loading: pos\n",
      "2024-04-06 18:40:19 INFO: Loading: mwt\n",
      "2024-04-06 18:40:19 INFO: Loading: mwt\n",
      "2024-04-06 18:40:19 INFO: Loading: mwt\n",
      "2024-04-06 18:40:19 INFO: Loading: mwt\n",
      "2024-04-06 18:40:19 INFO: Loading: pos\n",
      "2024-04-06 18:40:19 INFO: Loading: pos\n",
      "2024-04-06 18:40:19 INFO: Loading: pos\n",
      "2024-04-06 18:40:19 INFO: Loading: pos\n",
      "2024-04-06 18:40:19 INFO: Loading: mwt\n",
      "2024-04-06 18:40:19 INFO: Loading: pos\n",
      "2024-04-06 18:40:19 INFO: Loading: lemma\n",
      "2024-04-06 18:40:20 INFO: Done loading processors!\n",
      "2024-04-06 18:40:20 INFO: Loading: lemma\n",
      "2024-04-06 18:40:20 INFO: Loading: lemma\n",
      "2024-04-06 18:40:20 INFO: Loading: lemma\n",
      "2024-04-06 18:40:20 INFO: Loading: lemma\n",
      "2024-04-06 18:40:20 INFO: Loading: lemma\n",
      "2024-04-06 18:40:20 INFO: Done loading processors!\n",
      "2024-04-06 18:40:20 INFO: Done loading processors!\n",
      "2024-04-06 18:40:20 INFO: Done loading processors!\n",
      "2024-04-06 18:40:20 INFO: Done loading processors!\n",
      "2024-04-06 18:40:20 INFO: Done loading processors!\n",
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['τρίτη'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessed and saved!\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder('models/octis/data/dataset')\n",
    "print(\"Dataset found cached - loading...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset.get_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_npmi = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='c_npmi')\n",
    "coherence_cv = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='c_v')\n",
    "coherence_umass = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='u_mass')\n",
    "coherence_uci = Coherence(texts=corpus, topk=TOP_K, processes=NUM_PROCESSES, measure='c_uci')\n",
    "\n",
    "diversity_topic = TopicDiversity(topk=TOP_K)\n",
    "diversity_kl = KLDivergence()\n",
    "\n",
    "similarity_rbo = RBO(topk=TOP_K)\n",
    "similarity_pjs = PairwiseJaccardSimilarity()\n",
    "\n",
    "significance_kluni = KL_uniform()\n",
    "\n",
    "other_metrics = [coherence_npmi, coherence_umass, coherence_uci, diversity_topic, diversity_kl, similarity_rbo, similarity_pjs, significance_kluni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"coherence_npmi\": coherence_npmi, \"coherence_cv\": coherence_cv, \"coherence_umass\": coherence_umass, \"coherence_uci\": coherence_uci, \"diversity_topic\": diversity_topic, \"diversity_kl\": diversity_kl, \"similarity_rbo\": similarity_rbo, \"similarity_pjs\": similarity_pjs, \"significance_kluni\": significance_kluni}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LSI(**lsi_params)\n",
    "lda_model = LDA(**lda_params)\n",
    "hdp_model = HDP(**hdp_params)\n",
    "nmf_model = NMF(**nmf_params)\n",
    "neural_lda_model = NeuralLDA(**neural_lda_params)\n",
    "prod_lda_model = ProdLDA(**prod_lda_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"lsi\": lsi_model, \"lda\": lda_model, \"hdp\": hdp_model, \"nmf\": nmf_model, \"neural_lda\": neural_lda_model, \"prod_lda\": prod_lda_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = OCTISModelEvaluator(dataset=dataset, \n",
    "                                models=models,\n",
    "                                metrics=metrics,\n",
    "                                topics=NUM_TOPICS,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/200]\tSamples: [1439/287800]\tTrain Loss: 3575.99102023975\tTime: 0:00:00.177247\n",
      "Epoch: [1/200]\tSamples: [160/32000]\tValidation Loss: 1167837.0560546876\tTime: 0:00:00.005994\n",
      "Epoch: [2/200]\tSamples: [2878/287800]\tTrain Loss: 3376.282645283183\tTime: 0:00:00.120058\n",
      "Epoch: [2/200]\tSamples: [160/32000]\tValidation Loss: 43017.15424804688\tTime: 0:00:00.006124\n",
      "Epoch: [3/200]\tSamples: [4317/287800]\tTrain Loss: 3360.946257166435\tTime: 0:00:00.126054\n",
      "Epoch: [3/200]\tSamples: [160/32000]\tValidation Loss: 1322247197.6279786\tTime: 0:00:00.006747\n",
      "Epoch: [4/200]\tSamples: [5756/287800]\tTrain Loss: 3290.535061240445\tTime: 0:00:00.121633\n",
      "Epoch: [4/200]\tSamples: [160/32000]\tValidation Loss: 35319.64255371094\tTime: 0:00:00.005842\n",
      "Epoch: [5/200]\tSamples: [7195/287800]\tTrain Loss: 3251.2212473940235\tTime: 0:00:00.130142\n",
      "Epoch: [5/200]\tSamples: [160/32000]\tValidation Loss: 5965.650048828125\tTime: 0:00:00.006255\n",
      "Epoch: [6/200]\tSamples: [8634/287800]\tTrain Loss: 3267.123164958304\tTime: 0:00:00.129418\n",
      "Epoch: [6/200]\tSamples: [160/32000]\tValidation Loss: 4668.293603515625\tTime: 0:00:00.006195\n",
      "Epoch: [7/200]\tSamples: [10073/287800]\tTrain Loss: 3203.763409920083\tTime: 0:00:00.117776\n",
      "Epoch: [7/200]\tSamples: [160/32000]\tValidation Loss: 4885.9697265625\tTime: 0:00:00.006763\n",
      "Epoch: [8/200]\tSamples: [11512/287800]\tTrain Loss: 3189.7120233234887\tTime: 0:00:00.117145\n",
      "Epoch: [8/200]\tSamples: [160/32000]\tValidation Loss: 4493.45517578125\tTime: 0:00:00.007404\n",
      "Epoch: [9/200]\tSamples: [12951/287800]\tTrain Loss: 3178.711561848506\tTime: 0:00:00.122470\n",
      "Epoch: [9/200]\tSamples: [160/32000]\tValidation Loss: 4528.89599609375\tTime: 0:00:00.008330\n",
      "Epoch: [10/200]\tSamples: [14390/287800]\tTrain Loss: 3185.0609961344685\tTime: 0:00:00.114718\n",
      "Epoch: [10/200]\tSamples: [160/32000]\tValidation Loss: 5964.74462890625\tTime: 0:00:00.004951\n",
      "Epoch: [11/200]\tSamples: [15829/287800]\tTrain Loss: 3154.060116617443\tTime: 0:00:00.121373\n",
      "Epoch: [11/200]\tSamples: [160/32000]\tValidation Loss: 6820.08427734375\tTime: 0:00:00.006163\n",
      "Epoch: [12/200]\tSamples: [17268/287800]\tTrain Loss: 3248.149832783183\tTime: 0:00:00.119200\n",
      "Epoch: [12/200]\tSamples: [160/32000]\tValidation Loss: 5923.919140625\tTime: 0:00:00.005262\n",
      "Epoch: [13/200]\tSamples: [18707/287800]\tTrain Loss: 3140.776553813412\tTime: 0:00:00.124176\n",
      "Epoch: [13/200]\tSamples: [160/32000]\tValidation Loss: 5625.78828125\tTime: 0:00:00.006401\n",
      "Early stopping\n",
      "Epoch: [1/50]\tSamples: [1439/71950]\tTrain Loss: 3657.6653057678946\tTime: 0:00:00.111974\n",
      "Epoch: [1/50]\tSamples: [160/8000]\tValidation Loss: 214764.27827148436\tTime: 0:00:00.005640\n",
      "Epoch: [2/50]\tSamples: [2878/71950]\tTrain Loss: 3461.9631851546214\tTime: 0:00:00.117429\n",
      "Epoch: [2/50]\tSamples: [160/8000]\tValidation Loss: 60993.29169921875\tTime: 0:00:00.006449\n",
      "Epoch: [3/50]\tSamples: [4317/71950]\tTrain Loss: 3432.759555246699\tTime: 0:00:00.114366\n",
      "Epoch: [3/50]\tSamples: [160/8000]\tValidation Loss: 49889.535888671875\tTime: 0:00:00.007029\n",
      "Epoch: [4/50]\tSamples: [5756/71950]\tTrain Loss: 3271.9638149322445\tTime: 0:00:00.109511\n",
      "Epoch: [4/50]\tSamples: [160/8000]\tValidation Loss: 11644.044873046874\tTime: 0:00:00.005855\n",
      "Epoch: [5/50]\tSamples: [7195/71950]\tTrain Loss: 3248.7242225503824\tTime: 0:00:00.106483\n",
      "Epoch: [5/50]\tSamples: [160/8000]\tValidation Loss: 14241.89453125\tTime: 0:00:00.004678\n",
      "Epoch: [6/50]\tSamples: [8634/71950]\tTrain Loss: 3227.545805463864\tTime: 0:00:00.106998\n",
      "Epoch: [6/50]\tSamples: [160/8000]\tValidation Loss: 44236.516015625\tTime: 0:00:00.006251\n",
      "Epoch: [7/50]\tSamples: [10073/71950]\tTrain Loss: 3276.2170778318277\tTime: 0:00:00.113682\n",
      "Epoch: [7/50]\tSamples: [160/8000]\tValidation Loss: 27465.696533203125\tTime: 0:00:00.006865\n",
      "Epoch: [8/50]\tSamples: [11512/71950]\tTrain Loss: 3216.8169953092424\tTime: 0:00:00.098691\n",
      "Epoch: [8/50]\tSamples: [160/8000]\tValidation Loss: 4943.116796875\tTime: 0:00:00.005266\n",
      "Epoch: [9/50]\tSamples: [12951/71950]\tTrain Loss: 3315.9468380820012\tTime: 0:00:00.104972\n",
      "Epoch: [9/50]\tSamples: [160/8000]\tValidation Loss: 5199.9634765625\tTime: 0:00:00.007528\n",
      "Epoch: [10/50]\tSamples: [14390/71950]\tTrain Loss: 3213.713614054899\tTime: 0:00:00.101277\n",
      "Epoch: [10/50]\tSamples: [160/8000]\tValidation Loss: 4669.717919921875\tTime: 0:00:00.004881\n",
      "Epoch: [11/50]\tSamples: [15829/71950]\tTrain Loss: 3204.067690236275\tTime: 0:00:00.107956\n",
      "Epoch: [11/50]\tSamples: [160/8000]\tValidation Loss: 3825.84853515625\tTime: 0:00:00.005639\n",
      "Epoch: [12/50]\tSamples: [17268/71950]\tTrain Loss: 3183.4324889246004\tTime: 0:00:00.106801\n",
      "Epoch: [12/50]\tSamples: [160/8000]\tValidation Loss: 3272.05166015625\tTime: 0:00:00.007524\n",
      "Epoch: [13/50]\tSamples: [18707/71950]\tTrain Loss: 3180.5438998436416\tTime: 0:00:00.108506\n",
      "Epoch: [13/50]\tSamples: [160/8000]\tValidation Loss: 3284.6279052734376\tTime: 0:00:00.004621\n",
      "Epoch: [14/50]\tSamples: [20146/71950]\tTrain Loss: 3204.911141634816\tTime: 0:00:00.090495\n",
      "Epoch: [14/50]\tSamples: [160/8000]\tValidation Loss: 3325.3908203125\tTime: 0:00:00.005338\n",
      "Epoch: [15/50]\tSamples: [21585/71950]\tTrain Loss: 3221.422352762335\tTime: 0:00:00.095866\n",
      "Epoch: [15/50]\tSamples: [160/8000]\tValidation Loss: 3371.21474609375\tTime: 0:00:00.005354\n",
      "Epoch: [16/50]\tSamples: [23024/71950]\tTrain Loss: 3174.4078190149407\tTime: 0:00:00.094449\n",
      "Epoch: [16/50]\tSamples: [160/8000]\tValidation Loss: 3177.475634765625\tTime: 0:00:00.005157\n",
      "Epoch: [17/50]\tSamples: [24463/71950]\tTrain Loss: 3157.7162688933286\tTime: 0:00:00.090552\n",
      "Epoch: [17/50]\tSamples: [160/8000]\tValidation Loss: 3153.17890625\tTime: 0:00:00.004801\n",
      "Epoch: [18/50]\tSamples: [25902/71950]\tTrain Loss: 3154.2714558721336\tTime: 0:00:00.095074\n",
      "Epoch: [18/50]\tSamples: [160/8000]\tValidation Loss: 3134.36650390625\tTime: 0:00:00.004753\n",
      "Epoch: [19/50]\tSamples: [27341/71950]\tTrain Loss: 3155.8055398714387\tTime: 0:00:00.099322\n",
      "Epoch: [19/50]\tSamples: [160/8000]\tValidation Loss: 3000.212841796875\tTime: 0:00:00.005625\n",
      "Epoch: [20/50]\tSamples: [28780/71950]\tTrain Loss: 3144.2325291000693\tTime: 0:00:00.119364\n",
      "Epoch: [20/50]\tSamples: [160/8000]\tValidation Loss: 3153.307666015625\tTime: 0:00:00.006890\n",
      "Epoch: [21/50]\tSamples: [30219/71950]\tTrain Loss: 3145.610297949965\tTime: 0:00:00.099601\n",
      "Epoch: [21/50]\tSamples: [160/8000]\tValidation Loss: 3019.76630859375\tTime: 0:00:00.005753\n",
      "Epoch: [22/50]\tSamples: [31658/71950]\tTrain Loss: 3136.4951735145933\tTime: 0:00:00.093733\n",
      "Epoch: [22/50]\tSamples: [160/8000]\tValidation Loss: 3019.916015625\tTime: 0:00:00.006434\n",
      "Epoch: [23/50]\tSamples: [33097/71950]\tTrain Loss: 3129.9151483234887\tTime: 0:00:00.092741\n",
      "Epoch: [23/50]\tSamples: [160/8000]\tValidation Loss: 3005.016943359375\tTime: 0:00:00.004242\n",
      "Epoch: [24/50]\tSamples: [34536/71950]\tTrain Loss: 3117.4687065670605\tTime: 0:00:00.086824\n",
      "Epoch: [24/50]\tSamples: [160/8000]\tValidation Loss: 2966.25068359375\tTime: 0:00:00.004675\n",
      "Epoch: [25/50]\tSamples: [35975/71950]\tTrain Loss: 3113.084194753301\tTime: 0:00:00.089303\n",
      "Epoch: [25/50]\tSamples: [160/8000]\tValidation Loss: 2974.251611328125\tTime: 0:00:00.004448\n",
      "Epoch: [26/50]\tSamples: [37414/71950]\tTrain Loss: 3102.276906706046\tTime: 0:00:00.122599\n",
      "Epoch: [26/50]\tSamples: [160/8000]\tValidation Loss: 2985.04248046875\tTime: 0:00:00.005662\n",
      "Epoch: [27/50]\tSamples: [38853/71950]\tTrain Loss: 3113.7253735232803\tTime: 0:00:00.102559\n",
      "Epoch: [27/50]\tSamples: [160/8000]\tValidation Loss: 2958.02998046875\tTime: 0:00:00.005724\n",
      "Epoch: [28/50]\tSamples: [40292/71950]\tTrain Loss: 3105.2556245656706\tTime: 0:00:00.102098\n",
      "Epoch: [28/50]\tSamples: [160/8000]\tValidation Loss: 2968.295703125\tTime: 0:00:00.004475\n",
      "Epoch: [29/50]\tSamples: [41731/71950]\tTrain Loss: 3103.4146325573315\tTime: 0:00:00.091823\n",
      "Epoch: [29/50]\tSamples: [160/8000]\tValidation Loss: 2952.233154296875\tTime: 0:00:00.005090\n",
      "Epoch: [30/50]\tSamples: [43170/71950]\tTrain Loss: 3106.7030327050034\tTime: 0:00:00.092538\n",
      "Epoch: [30/50]\tSamples: [160/8000]\tValidation Loss: 2967.490283203125\tTime: 0:00:00.004984\n",
      "Epoch: [31/50]\tSamples: [44609/71950]\tTrain Loss: 3086.2991280837387\tTime: 0:00:00.087758\n",
      "Epoch: [31/50]\tSamples: [160/8000]\tValidation Loss: 2964.72255859375\tTime: 0:00:00.005323\n",
      "Epoch: [32/50]\tSamples: [46048/71950]\tTrain Loss: 3085.0578852501735\tTime: 0:00:00.097758\n",
      "Epoch: [32/50]\tSamples: [160/8000]\tValidation Loss: 2949.57880859375\tTime: 0:00:00.006995\n",
      "Epoch: [33/50]\tSamples: [47487/71950]\tTrain Loss: 3081.934975460389\tTime: 0:00:00.094981\n",
      "Epoch: [33/50]\tSamples: [160/8000]\tValidation Loss: 2968.63623046875\tTime: 0:00:00.005525\n",
      "Epoch: [34/50]\tSamples: [48926/71950]\tTrain Loss: 3100.2009316365534\tTime: 0:00:00.096081\n",
      "Epoch: [34/50]\tSamples: [160/8000]\tValidation Loss: 3009.514208984375\tTime: 0:00:00.004545\n",
      "Epoch: [35/50]\tSamples: [50365/71950]\tTrain Loss: 3114.3365184155664\tTime: 0:00:00.088590\n",
      "Epoch: [35/50]\tSamples: [160/8000]\tValidation Loss: 2974.832421875\tTime: 0:00:00.005308\n",
      "Epoch: [36/50]\tSamples: [51804/71950]\tTrain Loss: 3072.0422331045866\tTime: 0:00:00.093058\n",
      "Epoch: [36/50]\tSamples: [160/8000]\tValidation Loss: 2961.761865234375\tTime: 0:00:00.005878\n",
      "Epoch: [37/50]\tSamples: [53243/71950]\tTrain Loss: 3106.254810198054\tTime: 0:00:00.092669\n",
      "Epoch: [37/50]\tSamples: [160/8000]\tValidation Loss: 2966.886279296875\tTime: 0:00:00.005056\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dion/Library/CloudStorage/GoogleDrive-dion.rigatos@gmail.com/My Drive/Archivio/University/Classes/Erasmus Courses/NLP/NLP Project/greek-pm-topic-modeling/src/models/octis/utils/model_evaluator.py:47: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.evaluation_df = pd.concat([self.evaluation_df, pd.DataFrame(model_metric_data)], ignore_index=True)\n",
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/octis/evaluation_metrics/diversity_metrics.py:244: RuntimeWarning: invalid value encountered in log\n",
      "  divergence = np.sum(P*np.log(P/Q))\n",
      "/Users/dion/.pyenv/versions/3.11.8/envs/nlp-env/lib/python3.11/site-packages/octis/evaluation_metrics/topic_significance_metrics.py:24: RuntimeWarning: invalid value encountered in log\n",
      "  divergence = np.sum(P*np.log(P/Q))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>coherence_npmi</th>\n",
       "      <th>coherence_cv</th>\n",
       "      <th>coherence_umass</th>\n",
       "      <th>coherence_uci</th>\n",
       "      <th>diversity_topic</th>\n",
       "      <th>diversity_kl</th>\n",
       "      <th>similarity_rbo</th>\n",
       "      <th>similarity_pjs</th>\n",
       "      <th>significance_kluni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lsi</td>\n",
       "      <td>0.016515</td>\n",
       "      <td>0.578025</td>\n",
       "      <td>-1.510241</td>\n",
       "      <td>-1.091888</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.383912</td>\n",
       "      <td>0.054179</td>\n",
       "      <td>0.035555</td>\n",
       "      <td>0.190096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lda</td>\n",
       "      <td>0.130490</td>\n",
       "      <td>0.678527</td>\n",
       "      <td>-1.265472</td>\n",
       "      <td>0.358107</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>2.359925</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>1.560585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hdp</td>\n",
       "      <td>-0.062434</td>\n",
       "      <td>0.490024</td>\n",
       "      <td>-2.316952</td>\n",
       "      <td>-3.008380</td>\n",
       "      <td>0.542667</td>\n",
       "      <td>0.361988</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>0.213347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nmf</td>\n",
       "      <td>0.072090</td>\n",
       "      <td>0.618584</td>\n",
       "      <td>-1.250158</td>\n",
       "      <td>-0.343318</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>4.024918</td>\n",
       "      <td>0.041427</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>2.102304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neural_lda</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>0.505895</td>\n",
       "      <td>-2.013145</td>\n",
       "      <td>-1.395140</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.144312</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.681478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prod_lda</td>\n",
       "      <td>-0.040740</td>\n",
       "      <td>0.618758</td>\n",
       "      <td>-2.785769</td>\n",
       "      <td>-3.756963</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  coherence_npmi  coherence_cv  coherence_umass  coherence_uci  \\\n",
       "0         lsi        0.016515      0.578025        -1.510241      -1.091888   \n",
       "1         lda        0.130490      0.678527        -1.265472       0.358107   \n",
       "2         hdp       -0.062434      0.490024        -2.316952      -3.008380   \n",
       "3         nmf        0.072090      0.618584        -1.250158      -0.343318   \n",
       "4  neural_lda       -0.037495      0.505895        -2.013145      -1.395140   \n",
       "5    prod_lda       -0.040740      0.618758        -2.785769      -3.756963   \n",
       "\n",
       "   diversity_topic  diversity_kl  similarity_rbo  similarity_pjs  \\\n",
       "0         0.566667      0.383912        0.054179        0.035555   \n",
       "1         0.826667      2.359925        0.012845        0.011574   \n",
       "2         0.542667      0.361988        0.016444        0.013665   \n",
       "3         0.606667      4.024918        0.041427        0.033569   \n",
       "4         0.960000      1.144312        0.001852        0.002355   \n",
       "5         0.906667           NaN        0.004984        0.005760   \n",
       "\n",
       "   significance_kluni  \n",
       "0            0.190096  \n",
       "1            1.560585  \n",
       "2            0.213347  \n",
       "3            2.102304  \n",
       "4            0.681478  \n",
       "5                 NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
