{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a671e359e5d8c5b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finding the Best Hyperparameters for BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7bb6e08577a63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this notebook we will try to find the best hyperparameters for our BERTopic model, by trying different configurations of UMAP and HDBSCAN models. Then we will evaluate each model based on both standard evaluation metrics and manual inspection of the topics created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eb939",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56643b81",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from models.bertopic.utils.data_loader import DataLoader\n",
    "from models.bertopic.utils.bertopic_evaluator import BERTopicModelEvaluator\n",
    "from models.bertopic.config.model import NUM_TOPICS, TOP_K, EMBEDDING_MODEL, vectorizer_params, c_tfidf_params, metrics\n",
    "from models.bertopic.config.optimization import all_config_combinations, algos_dict\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129e722882e061e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = DataLoader('data/data_speeches.csv', 'data/data_statements.csv')\n",
    "loader.process()\n",
    "\n",
    "train_docs, train_sentences = loader.get_train_data()\n",
    "val_docs, val_sentences = loader.get_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483df0325a7c35cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_datasets = {\n",
    "    'docs': train_docs,\n",
    "    'sentences': train_sentences\n",
    "}\n",
    "\n",
    "val_datasets = {\n",
    "    'docs': val_docs,\n",
    "    'sentences': val_sentences\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6850f97",
   "metadata": {},
   "source": [
    "For this step, we only need the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66810a73",
   "metadata": {},
   "source": [
    "## Constant Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20f629",
   "metadata": {},
   "source": [
    "We will use the same vectorizer, c-TF-IDF model and sentence transformer model for all our experiments. \n",
    "\n",
    "We're interesting in optimizing on the Dimensionality Reduction and Clustering models, so we will keep the rest of the pipeline constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504e80f2c0e4d0be",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(**vectorizer_params)\n",
    "ctfidf_model = ClassTfidfTransformer(**c_tfidf_params)\n",
    "st_model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d7c61fc44f47d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluating different UMAP and HDBSCAN configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580d89e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f382c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space = all_config_combinations()\n",
    "len(search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b31b1",
   "metadata": {},
   "source": [
    "### Document Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48084f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = 'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93a287cb8fdeb5d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for config in search_space:\n",
    "    dim_reduction_model = algos_dict[config['dim_reduction_model']](**config['dim_reduction_params'])\n",
    "    clustering_model = algos_dict[config['clustering_model']](**config['clustering_params'])\n",
    "        \n",
    "    model_name = f\"model_{config['dim_reduction_model']}_{config['dim_reduction_params']}_{config['clustering_model']}_{config['clustering_params']}\"\n",
    "\n",
    "\n",
    "    model = BERTopic(\n",
    "        umap_model=dim_reduction_model,\n",
    "        hdbscan_model=clustering_model,\n",
    "        embedding_model=EMBEDDING_MODEL,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        nr_topics=NUM_TOPICS,\n",
    "        top_n_words=TOP_K,\n",
    "    )\n",
    "    \n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68dba14b84c67bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = BERTopicModelEvaluator(\n",
    "                                   models=models, \n",
    "                                   metrics=metrics, \n",
    "                                   train_dataset=train_datasets[granularity],\n",
    "                                   val_dataset=val_datasets[granularity],\n",
    "                                   topics=NUM_TOPICS,\n",
    "                                   topk=TOP_K,\n",
    "                                   eval_type='val',\n",
    "                                   granularity=granularity\n",
    "                                   )                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb14361500f3ad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf654c",
   "metadata": {},
   "source": [
    "### Sentence Level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
