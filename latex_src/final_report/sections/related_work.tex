\section{Related Work}
\label{sec:related_work}
As it was previously mentioned, machine learning has become more versatile than ever when it comes to applications in under-represented languages. Topic Modeling heavily benefits from this versatility as it has applications in both supervised and unsupervised tasks - providing a relevant solution to the extraction of information from large corpora. 

As shown by \cite{Panagiotis;22}, state-of-the-art (SOTA) solutions such as BERTopic can lead to impressive results in language-specific tasks - something confirmed thanks to the availability of labels in their experiments. Their approach yielded acceptable quantitative metrics in both topic quality and classification of labeled corpora, while the qualitative aspect was also satisfactory. 

Our approach will rely heavily on manually gathered data from a specific domain (political publications) and in a strictly unsupervised context. On top of that, we aim to show that a thorough exploration of preprocessing techniques can significantly boost the performance of classic topic modeling algorithms. Additionally, we look for the optimal language-specific tools to help us achieve that which - in a way - evaluates them in a practical scenario. Finally, we will experiment generously with different modular components and hyperparameters in BERTopic, as well as with topic representation models for improved clarity in the outputs. Tackling this task with the big image in mind is very likely to yield interesting results at every single step of the analysis.